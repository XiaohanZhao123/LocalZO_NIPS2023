{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Serious of transformations\n",
    "* Step1: load from the tonic.datasets.Dataset\n",
    "* Step2: apply transformation defined in tonic.transforms, like Denoise, ToFrame\n",
    "* Step3: warp the dataset using a CachedDataset, which will cache the transformed data to disk\n",
    "* Step4: apply transformation to the frame (output from ToFrame), here we can use torch and torchvision transforms\n",
    "* Step5: warp the dataset using dataloader, but be aware of collate_fn, where we need to pad the frame to the same length\n",
    "* Step6: check if the result has shape [batch, time, channel, height, width] according to argument 'batch_first' in collate_fn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "array([(10, 30,    937, 1), (33, 20,   1030, 1), (12, 27,   1052, 1), ...,\n       ( 7, 15, 302706, 1), (26, 11, 303852, 1), (11, 17, 305341, 1)],\n      dtype=[('x', '<i8'), ('y', '<i8'), ('t', '<i8'), ('p', '<i8')])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import tonic\n",
    "\n",
    "dataset = tonic.datasets.NMNIST(save_to='./data', train=True)\n",
    "events, target = dataset[0]\n",
    "events"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tonic.transforms as transforms\n",
    "\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "# remove isolated events\n",
    "# sum a period of events into a frame\n",
    "frame_transform = transforms.Compose([\n",
    "    transforms.Denoise(filter_time=10000),\n",
    "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000),\n",
    "])\n",
    "trainset = tonic.datasets.NMNIST(save_to='./data', train=True, transform=frame_transform)\n",
    "testset = tonic.datasets.NMNIST(save_to='./data', train=False, transform=frame_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 311, 2, 34, 34])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./data/cache')\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./data/cache')\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(cached_trainset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=tonic.collation.PadTensors())\n",
    "test_loader = DataLoader(cached_testset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=tonic.collation.PadTensors())\n",
    "\n",
    "# check the shape of input\n",
    "next(iter(train_loader))[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([310, 128, 2, 34, 34])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import functools\n",
    "\n",
    "transform = tonic.transforms.Compose([\n",
    "    torch.from_numpy,\n",
    "    torchvision.transforms.RandomRotation([-10,10]),\n",
    "])\n",
    "\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./data/cache', transform=transform)\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./data/cache',)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(cached_trainset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "test_loader = DataLoader(cached_testset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4,\n",
    "                        collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "\n",
    "# check the shape of input\n",
    "next(iter(train_loader))[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# define the network\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as F\n",
    "from snntorch import spikeplot as splt\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# define the forward pass\n",
    "\n",
    "def forward(net, data):\n",
    "    spk_rec = []\n",
    "    utils.reset(net)\n",
    "\n",
    "    for step in range(data.size(0)):\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "\n",
    "    return torch.stack(spk_rec, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-2)\n",
    "loss_fn = F.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0 \n",
      "Train Loss: 30.90\n",
      "Accuracy: 7.03%\n",
      "\n",
      "Epoch 0, Iteration 1 \n",
      "Train Loss: 13.31\n",
      "Accuracy: 10.94%\n",
      "\n",
      "Epoch 0, Iteration 2 \n",
      "Train Loss: 17.79\n",
      "Accuracy: 13.28%\n",
      "\n",
      "Epoch 0, Iteration 3 \n",
      "Train Loss: 17.91\n",
      "Accuracy: 15.62%\n",
      "\n",
      "Epoch 0, Iteration 4 \n",
      "Train Loss: 13.51\n",
      "Accuracy: 11.72%\n",
      "\n",
      "Epoch 0, Iteration 5 \n",
      "Train Loss: 15.90\n",
      "Accuracy: 17.19%\n",
      "\n",
      "Epoch 0, Iteration 6 \n",
      "Train Loss: 14.81\n",
      "Accuracy: 14.06%\n",
      "\n",
      "Epoch 0, Iteration 7 \n",
      "Train Loss: 12.10\n",
      "Accuracy: 31.25%\n",
      "\n",
      "Epoch 0, Iteration 8 \n",
      "Train Loss: 12.38\n",
      "Accuracy: 39.84%\n",
      "\n",
      "Epoch 0, Iteration 9 \n",
      "Train Loss: 12.78\n",
      "Accuracy: 30.47%\n",
      "\n",
      "Epoch 0, Iteration 10 \n",
      "Train Loss: 12.97\n",
      "Accuracy: 27.34%\n",
      "\n",
      "Epoch 0, Iteration 11 \n",
      "Train Loss: 11.82\n",
      "Accuracy: 23.44%\n",
      "\n",
      "Epoch 0, Iteration 12 \n",
      "Train Loss: 12.14\n",
      "Accuracy: 31.25%\n",
      "\n",
      "Epoch 0, Iteration 13 \n",
      "Train Loss: 12.20\n",
      "Accuracy: 32.81%\n",
      "\n",
      "Epoch 0, Iteration 14 \n",
      "Train Loss: 11.70\n",
      "Accuracy: 25.00%\n",
      "\n",
      "Epoch 0, Iteration 15 \n",
      "Train Loss: 11.55\n",
      "Accuracy: 22.66%\n",
      "\n",
      "Epoch 0, Iteration 16 \n",
      "Train Loss: 11.53\n",
      "Accuracy: 23.44%\n",
      "\n",
      "Epoch 0, Iteration 17 \n",
      "Train Loss: 11.06\n",
      "Accuracy: 25.78%\n",
      "\n",
      "Epoch 0, Iteration 18 \n",
      "Train Loss: 11.39\n",
      "Accuracy: 22.66%\n",
      "\n",
      "Epoch 0, Iteration 19 \n",
      "Train Loss: 10.82\n",
      "Accuracy: 23.44%\n",
      "\n",
      "Epoch 0, Iteration 20 \n",
      "Train Loss: 10.77\n",
      "Accuracy: 29.69%\n",
      "\n",
      "Epoch 0, Iteration 21 \n",
      "Train Loss: 10.85\n",
      "Accuracy: 28.91%\n",
      "\n",
      "Epoch 0, Iteration 22 \n",
      "Train Loss: 10.25\n",
      "Accuracy: 24.22%\n",
      "\n",
      "Epoch 0, Iteration 23 \n",
      "Train Loss: 10.43\n",
      "Accuracy: 42.19%\n",
      "\n",
      "Epoch 0, Iteration 24 \n",
      "Train Loss: 9.82\n",
      "Accuracy: 45.31%\n",
      "\n",
      "Epoch 0, Iteration 25 \n",
      "Train Loss: 9.95\n",
      "Accuracy: 44.53%\n",
      "\n",
      "Epoch 0, Iteration 26 \n",
      "Train Loss: 9.97\n",
      "Accuracy: 43.75%\n",
      "\n",
      "Epoch 0, Iteration 27 \n",
      "Train Loss: 9.49\n",
      "Accuracy: 43.75%\n",
      "\n",
      "Epoch 0, Iteration 28 \n",
      "Train Loss: 9.35\n",
      "Accuracy: 53.12%\n",
      "\n",
      "Epoch 0, Iteration 29 \n",
      "Train Loss: 9.40\n",
      "Accuracy: 44.53%\n",
      "\n",
      "Epoch 0, Iteration 30 \n",
      "Train Loss: 9.02\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 0, Iteration 31 \n",
      "Train Loss: 8.98\n",
      "Accuracy: 57.03%\n",
      "\n",
      "Epoch 0, Iteration 32 \n",
      "Train Loss: 9.49\n",
      "Accuracy: 55.47%\n",
      "\n",
      "Epoch 0, Iteration 33 \n",
      "Train Loss: 9.42\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 0, Iteration 34 \n",
      "Train Loss: 9.20\n",
      "Accuracy: 50.78%\n",
      "\n",
      "Epoch 0, Iteration 35 \n",
      "Train Loss: 8.61\n",
      "Accuracy: 59.38%\n",
      "\n",
      "Epoch 0, Iteration 36 \n",
      "Train Loss: 8.70\n",
      "Accuracy: 55.47%\n",
      "\n",
      "Epoch 0, Iteration 37 \n",
      "Train Loss: 8.33\n",
      "Accuracy: 60.16%\n",
      "\n",
      "Epoch 0, Iteration 38 \n",
      "Train Loss: 8.29\n",
      "Accuracy: 58.59%\n",
      "\n",
      "Epoch 0, Iteration 39 \n",
      "Train Loss: 8.55\n",
      "Accuracy: 53.12%\n",
      "\n",
      "Epoch 0, Iteration 40 \n",
      "Train Loss: 8.46\n",
      "Accuracy: 52.34%\n",
      "\n",
      "Epoch 0, Iteration 41 \n",
      "Train Loss: 7.82\n",
      "Accuracy: 60.94%\n",
      "\n",
      "Epoch 0, Iteration 42 \n",
      "Train Loss: 7.83\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 0, Iteration 43 \n",
      "Train Loss: 8.07\n",
      "Accuracy: 64.84%\n",
      "\n",
      "Epoch 0, Iteration 44 \n",
      "Train Loss: 7.71\n",
      "Accuracy: 65.62%\n",
      "\n",
      "Epoch 0, Iteration 45 \n",
      "Train Loss: 7.65\n",
      "Accuracy: 66.41%\n",
      "\n",
      "Epoch 0, Iteration 46 \n",
      "Train Loss: 7.72\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 0, Iteration 47 \n",
      "Train Loss: 7.27\n",
      "Accuracy: 71.88%\n",
      "\n",
      "Epoch 0, Iteration 48 \n",
      "Train Loss: 7.62\n",
      "Accuracy: 62.50%\n",
      "\n",
      "Epoch 0, Iteration 49 \n",
      "Train Loss: 7.25\n",
      "Accuracy: 68.75%\n",
      "\n",
      "Epoch 0, Iteration 50 \n",
      "Train Loss: 7.14\n",
      "Accuracy: 74.22%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "num_iters = 50\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec = forward(net, data)\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
    "\n",
    "        acc = F.accuracy_rate(spk_rec, targets)\n",
    "        acc_hist.append(acc)\n",
    "        print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "        # training loop breaks after 50 iterations\n",
    "        if i == num_iters:\n",
    "          break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-xiaohan-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-xiaohan] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}