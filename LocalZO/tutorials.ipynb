{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training the Spconv\n",
    "This tutorial aims at twofold: First, we introduce how to construct and train network with spconv and how to glue the SNN neurons and spconv layers together. Second, we introduce how replace the snn neurons using surrogate gradient with Local ZO neurons.\n",
    "## 1 Introduction for Components\n",
    "### 1.1 Spconv\n",
    "Spconv are a pytorch library for sparse convolution, we use for conv layers, batch norm layers and pooling layers.\n",
    "GitHub homepage: https://github.com/traveller59/spconv\n",
    "### 1.2 LocalZO.conv_models\n",
    "Implementations of Spike Neurons (So far, only LIF), that can glue between Spconv layers\n",
    "\n",
    "## 2 Training the Spconv\n",
    "### 2.1 Data loading\n",
    "first, let's load the data using tonic. Details can be found in train_with_torch_nuro.ipynb, so we just skip it here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size: 60000 testset size: 10000 type of dataset <class 'numpy.ndarray'> shape (298, 2, 34, 34)\n"
     ]
    }
   ],
   "source": [
    "# set the gpu device\n",
    "gpu_idx = '3'\n",
    "import os\n",
    "from tonic.datasets import NMNIST\n",
    "import tonic\n",
    "from tonic import transforms\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_idx\n",
    "\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "# remove isolated events\n",
    "# sum a period of events into a frame\n",
    "frame_transform = transforms.Compose([\n",
    "    transforms.Denoise(filter_time=10000),\n",
    "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000),\n",
    "])  # the output of ToFrame is a tuple of (frame, label), where frame is np.ndarray\n",
    "\n",
    "trainset = tonic.datasets.NMNIST(save_to='/home/zxh/data', train=True, transform=frame_transform)\n",
    "testset = tonic.datasets.NMNIST(save_to='/home/zxh/data', train=False, transform=frame_transform)\n",
    "print('trainset size:', len(trainset), 'testset size:', len(testset), 'type of dataset', type(trainset[0][0]), 'shape', trainset[0][0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Define the network\n",
    "The construction of a Spconv network is basically same with constructing any torch.nn networks, except for a few things to notice:\n",
    "* The computation is time-first, and at the end of LIF layer we reshape the input into [time*batch, *inputs] before feeding into spconv network to improve the performance. So, we need to reshape it back before output.\n",
    "* The input of a Spconv network is a sparse tensor, constructed by spconv.SparseConvTensor.from_dense()\n",
    "* The LeakyPlain (implemented in LocalZO.conv_models.neurons) is a spike neuron that can glue between Spconv layers. It needs to specify the batch_size, u_th and beta. Batch size is used to reshape input and output, u_th and beta are parameters of LIF neuron.\n",
    "* The output should be a tensor with shape (time, batch, *inputs).\n",
    "\n",
    "**Important:** The spconv library treat empty input (i.e. input with only zeros) as an error\n",
    "Usually this will not happen, if so, we will get *CUDA kernel launch blocks must be positive, but got N= 0*. and please set appropriate u_th and beta to make at least one spike fire during the time stamps. Details can be found in : https://github.com/traveller59/spconv/blob/master/docs/COMMON_PROBLEMS.md\n",
    "\n",
    "\n",
    "**Not so Important** if just profile the network with only fc layers, ... just go head like constructing normal torch.nn networks anyway, not forget to reshape it back!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleNet(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): SparseConv2d(2, 16, kernel_size=[5, 5], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.Native)\n",
      "    (1): SparseBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SparseMaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=[0, 0], dilation=[1, 1], algo=ConvAlgo.MaskImplicitGemm)\n",
      "    (3): LeakyPlain()\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): SparseConv2d(16, 32, kernel_size=[5, 5], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.Native)\n",
      "    (1): SparseBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SparseMaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=[0, 0], dilation=[1, 1], algo=ConvAlgo.MaskImplicitGemm)\n",
      "    (3): LeakyPlain()\n",
      "  )\n",
      "  (to_dense): ToDense()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=800, out_features=10, bias=True)\n",
      "    (1): LeakyPlain()\n",
      "  )\n",
      ")\n",
      "conv_block1.0.weight torch.Size([16, 5, 5, 2])\n",
      "conv_block1.0.bias torch.Size([16])\n",
      "conv_block1.1.weight torch.Size([16])\n",
      "conv_block1.1.bias torch.Size([16])\n",
      "conv_block2.0.weight torch.Size([32, 5, 5, 16])\n",
      "conv_block2.0.bias torch.Size([32])\n",
      "conv_block2.1.weight torch.Size([32])\n",
      "conv_block2.1.bias torch.Size([32])\n",
      "fc.0.weight torch.Size([10, 800])\n",
      "fc.0.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from spconv import pytorch as spconv  # pay attention to the spconv.pytorch\n",
    "from conv_models.neurons import LeakyPlain\n",
    "\n",
    "\n",
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self, batch_size, u_th, beta, conv_algorithm = spconv.ConvAlgo.Native):\n",
    "        super(ExampleNet, self).__init__()\n",
    "        self.batch_size= batch_size\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            spconv.SparseConv2d(2, 16, 5, bias=True, algo=conv_algorithm),\n",
    "            spconv.SparseBatchNorm(16, eps=1e-5, momentum=0.1),\n",
    "            spconv.SparseMaxPool2d(2, stride=2),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size),\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            spconv.SparseConv2d(16, 32, 5, bias=True, algo=conv_algorithm),\n",
    "            spconv.SparseBatchNorm(32, eps=1e-5, momentum=0.1),\n",
    "            spconv.SparseMaxPool2d(2, stride=2),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size),\n",
    "        )\n",
    "        self.to_dense = spconv.ToDense() # convert the sparse tensor to dense tensor\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*5*5, 10),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, spconv.SparseConvTensor)\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.to_dense(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.batch_size, 10)  # reshape back into time, batch, *inputs\n",
    "        return x\n",
    "\n",
    "batch_size = 128\n",
    "net = ExampleNet(batch_size=batch_size, u_th=0.8, beta=0.6).cuda()\n",
    "print(net)\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Define the loss function and optimizer\n",
    "we use loss function from snntorch, and optimizer from torch.optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from snntorch import functional as SF\n",
    "import torch\n",
    "\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "acc_fn = SF.accuracy_rate\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Cache dataset to accelerate training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cache_transform = tonic.transforms.Compose([\n",
    "    torch.from_numpy,\n",
    "    torchvision.transforms.RandomRotation([-10,10]),\n",
    "])\n",
    "\n",
    "epoch_num = 5\n",
    "cached_trainset = tonic.DiskCachedDataset(trainset, cache_path='./data/cache', transform=cache_transform)\n",
    "cached_testset = tonic.DiskCachedDataset(testset, cache_path='./data/cache',)\n",
    "\n",
    "train_loader = DataLoader(cached_trainset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True, collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "test_loader = DataLoader(cached_testset, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=True,\n",
    "                         collate_fn=tonic.collation.PadTensors(batch_first=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6 Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 22:43:12.713651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 22:43:17.745580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-05-04 22:43:17.745996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-05-04 22:43:17.746026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 loss 26.820280075073242 acc 0.140625\n",
      "epoch 0 batch 10 loss 13.462841987609863 acc 0.15625\n",
      "epoch 0 batch 20 loss 9.124115943908691 acc 0.359375\n",
      "epoch 0 batch 30 loss 7.92097806930542 acc 0.53125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 24>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m                 \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m>\u001B[39m max_iter:\n\u001B[1;32m     22\u001B[0m                     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[43mtrain_net_work\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mtrain_net_work\u001B[0;34m(net, train_loader, test_loader, epoch_num, max_iter)\u001B[0m\n\u001B[1;32m     10\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 12\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, labels)\n\u001B[1;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mExampleNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, spconv\u001B[38;5;241m.\u001B[39mSparseConvTensor)\n\u001B[0;32m---> 32\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv_block1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_block2(x)\n\u001B[1;32m     34\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_dense(x)\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/spconv/pytorch/pool.py:184\u001B[0m, in \u001B[0;36mSparseMaxPool.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39m_timer\u001B[38;5;241m.\u001B[39mnamespace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgen_pairs\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 184\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_indice_pairs_implicit_gemm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m            \u001B[49m\u001B[43mspatial_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malgo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m            \u001B[49m\u001B[43mksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdilation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m            \u001B[49m\u001B[43mout_padding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout_padding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubm\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m            \u001B[49m\u001B[43malloc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrust_allocator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     outids \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    199\u001B[0m     num_inds_per_loc \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/spconv/pytorch/ops.py:628\u001B[0m, in \u001B[0;36mget_indice_pairs_implicit_gemm\u001B[0;34m(indices, batch_size, spatial_shape, algo, ksize, stride, padding, dilation, out_padding, subm, transpose, is_train, alloc, timer, num_out_act_bound, direct_table, do_sort)\u001B[0m\n\u001B[1;32m    624\u001B[0m uniq_cnt \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros([\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    625\u001B[0m                        dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint32,\n\u001B[1;32m    626\u001B[0m                        device\u001B[38;5;241m=\u001B[39mindices\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    627\u001B[0m uniq_cnt_tv \u001B[38;5;241m=\u001B[39m torch_tensor_to_tv(uniq_cnt)\n\u001B[0;32m--> 628\u001B[0m num_act_out \u001B[38;5;241m=\u001B[39m \u001B[43mSpconvOps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique_hash\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhashdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhashdata_k_tv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mhashdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhashdata_v_tv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43muniq_cnt_tv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mindice_pairs_uniq_tv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mnum_out_act_bound\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    633\u001B[0m uniq_out_indices_offset_tv \u001B[38;5;241m=\u001B[39m indice_pairs_uniq_tv\n\u001B[1;32m    634\u001B[0m raw_out_indices_offset_tv \u001B[38;5;241m=\u001B[39m indice_pairs_uniq_bkp_tv\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import time\n",
    "\n",
    "def train_net_work(net, train_loader, test_loader=None, epoch_num=1, max_iter=200):\n",
    "    with SummaryWriter(comment='spconv', log_dir='./output/spconv') as writer:\n",
    "        for epoch in range(epoch_num):\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs = inputs.view(-1, *inputs.shape[2:]).transpose(1, 3).cuda()\n",
    "                inputs = spconv.SparseConvTensor.from_dense(inputs)\n",
    "                labels = labels.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    writer.add_scalar('loss', loss.item(), epoch * len(train_loader) + i)\n",
    "                    writer.add_scalar('acc', acc_fn(outputs, labels).item(), epoch * len(train_loader) + i)\n",
    "                    print('epoch', epoch, 'batch', i, 'loss', loss.item(), 'acc', acc_fn(outputs, labels).item())\n",
    "                if i > max_iter:\n",
    "                    break\n",
    "\n",
    "train_net_work(net, train_loader, test_loader, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Training with LocalZO neurons\n",
    "### 3.1 Implementation Details\n",
    "The LocalZO neurons use random sampler to generate random tangents to approximate gradient\n",
    "Since the sampling technique varies, to instantiate a LocalZo neuron, we need to provide a sampler. For customized sampler, we recommend to inherit the base class `BaseSampler` and implement the `generate_random_tangents` method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleNetLocalZO(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): SparseConv2d(2, 16, kernel_size=[5, 5], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.Native)\n",
      "    (1): SparseBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SparseMaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=[0, 0], dilation=[1, 1], algo=ConvAlgo.MaskImplicitGemm)\n",
      "    (3): LeakeyZOPlain()\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): SparseConv2d(16, 32, kernel_size=[5, 5], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.Native)\n",
      "    (1): SparseBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SparseMaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=[0, 0], dilation=[1, 1], algo=ConvAlgo.MaskImplicitGemm)\n",
      "    (3): LeakeyZOPlain()\n",
      "  )\n",
      "  (to_dense): ToDense()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=800, out_features=10, bias=True)\n",
      "    (1): LeakyPlain()\n",
      "  )\n",
      ")\n",
      "conv_block1.0.weight torch.Size([16, 5, 5, 2])\n",
      "conv_block1.0.bias torch.Size([16])\n",
      "conv_block1.1.weight torch.Size([16])\n",
      "conv_block1.1.bias torch.Size([16])\n",
      "conv_block2.0.weight torch.Size([32, 5, 5, 16])\n",
      "conv_block2.0.bias torch.Size([32])\n",
      "conv_block2.1.weight torch.Size([32])\n",
      "conv_block2.1.bias torch.Size([32])\n",
      "fc.0.weight torch.Size([10, 800])\n",
      "fc.0.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "from conv_models.neurons import LeakeyZOPlain\n",
    "from conv_models.samplers import NormalSampler, BaseSampler\n",
    "\n",
    "\n",
    "class ExampleNetLocalZO(nn.Module):\n",
    "    def __init__(self, batch_size, u_th, beta, conv_algorithm = spconv.ConvAlgo.Native, random_sampler: BaseSampler=NormalSampler, sample_num=1):\n",
    "        super(ExampleNetLocalZO, self).__init__()\n",
    "        self.batch_size= batch_size\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            spconv.SparseConv2d(2, 16, 5, bias=True, algo=conv_algorithm),\n",
    "            spconv.SparseBatchNorm(16, eps=1e-5, momentum=0.1),\n",
    "            spconv.SparseMaxPool2d(2, stride=2),\n",
    "            LeakeyZOPlain(u_th=u_th, beta=beta, batch_size=batch_size, random_sampler=random_sampler(),sample_num=sample_num)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            spconv.SparseConv2d(16, 32, 5, bias=True, algo=conv_algorithm),\n",
    "            spconv.SparseBatchNorm(32, eps=1e-5, momentum=0.1),\n",
    "            spconv.SparseMaxPool2d(2, stride=2),\n",
    "            LeakeyZOPlain(u_th=u_th, beta=beta, batch_size=batch_size, random_sampler=random_sampler(),sample_num=sample_num)\n",
    "        )\n",
    "        self.to_dense = spconv.ToDense() # convert the sparse tensor to dense tensor\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*5*5, 10),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, spconv.SparseConvTensor)\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.to_dense(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.batch_size, 10)  # reshape back into time, batch, *inputs\n",
    "        return x\n",
    "\n",
    "net = ExampleNetLocalZO(batch_size=batch_size, u_th=1.0, beta=0.5).cuda()\n",
    "print(net)\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 loss 29.595436096191406 acc 0.1171875\n",
      "epoch 0 batch 10 loss 10.910920143127441 acc 0.21875\n",
      "epoch 0 batch 20 loss 9.111592292785645 acc 0.4609375\n",
      "epoch 0 batch 30 loss 8.278526306152344 acc 0.453125\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from snntorch import functional as SF\n",
    "import torch\n",
    "\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "acc_fn = SF.accuracy_rate\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3)\n",
    "\n",
    "train_net_work(net, train_loader, test_loader, 1, max_iter=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 Profile Sparsity\n",
    "If we need to profile the network, just pass profile=True in the neurons, then we can see the result. The result should be printed in the order of backward pass."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sparsity of the input grad is tensor(0.2963, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0383, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8068, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4533, device='cuda:0')\n",
      "epoch 0 batch 0 loss 30.725879669189453 acc 0.0703125\n",
      "the sparsity of the input grad is tensor(0.3211, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0390, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8204, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4752, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2917, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0396, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.7995, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4449, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2903, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0341, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8033, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4484, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2900, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0348, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8015, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4458, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2976, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0368, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8058, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4541, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2933, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0402, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8013, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4462, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2927, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0348, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8037, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4492, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2907, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0368, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8028, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4451, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2848, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0336, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8019, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4484, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2935, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0320, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8098, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4562, device='cuda:0')\n",
      "epoch 0 batch 10 loss 30.390073776245117 acc 0.1015625\n",
      "the sparsity of the input grad is tensor(0.2858, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0363, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8022, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4490, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2989, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0366, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8082, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4576, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2916, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0335, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8047, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4516, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2987, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0397, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8022, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4476, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.3012, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0377, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8096, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4606, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2973, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0360, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8058, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4490, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.3016, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0396, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8101, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4628, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2940, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0369, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8023, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4438, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2996, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0361, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8089, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4571, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2944, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0358, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8101, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4639, device='cuda:0')\n",
      "epoch 0 batch 20 loss 30.81368064880371 acc 0.078125\n",
      "the sparsity of the input grad is tensor(0.2926, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0389, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8020, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4454, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2995, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0367, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8099, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4606, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2912, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0362, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8025, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4474, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2989, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0358, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8048, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4482, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.3038, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0393, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8084, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4567, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2879, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0341, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8006, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4418, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2901, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0397, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8010, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4445, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2933, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0346, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8079, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4564, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2914, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0380, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8011, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4422, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.2975, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0350, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8042, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4519, device='cuda:0')\n",
      "epoch 0 batch 30 loss 30.83129119873047 acc 0.0625\n",
      "the sparsity of the input grad is tensor(0.2975, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.0405, device='cuda:0')\n",
      "the sparsity of the input grad is tensor(0.8056, device='cuda:0')\n",
      "the sparsity of the output grad is tensor(0.4518, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class ProfileNet(nn.Module):\n",
    "    def __init__(self, batch_size, u_th, beta, conv_algorithm = spconv.ConvAlgo.Native, random_sampler: BaseSampler=NormalSampler, sample_num=1):\n",
    "        super(ProfileNet, self).__init__()\n",
    "        self.batch_size= batch_size\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            spconv.SparseConv2d(2, 16, 5, bias=True, algo=conv_algorithm),\n",
    "            spconv.SparseBatchNorm(16, eps=1e-5, momentum=0.1),\n",
    "            spconv.SparseMaxPool2d(2, stride=2),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size, profile=True)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            spconv.SparseConv2d(16, 32, 5, bias=True, algo=conv_algorithm),\n",
    "            spconv.SparseBatchNorm(32, eps=1e-5, momentum=0.1),\n",
    "            spconv.SparseMaxPool2d(2, stride=2),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size, profile=True)\n",
    "        )\n",
    "        self.to_dense = spconv.ToDense() # convert the sparse tensor to dense tensor\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*5*5, 10),\n",
    "            LeakyPlain(u_th=u_th, beta=beta, batch_size=batch_size, profile=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, spconv.SparseConvTensor)\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.to_dense(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.batch_size, 10)  # reshape back into time, batch, *inputs\n",
    "        return x\n",
    "\n",
    "net = ProfileNet(batch_size=batch_size, u_th=1.0, beta=0.5).cuda()\n",
    "train_net_work(net, train_loader, test_loader, 1, max_iter=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we can see a decrease of sparsity here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-xiaohan-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-xiaohan] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}