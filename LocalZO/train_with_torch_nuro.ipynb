{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Serious of transformations using tonic\n",
    "* Step1: load from the tonic.datasets.Dataset\n",
    "* Step2: apply transformation defined in tonic.transforms, like Denoise, ToFrame\n",
    "* Step3: warp the dataset using a CachedDataset, which will cache the transformed data to disk\n",
    "* Step4: apply transformation to the frame (output from ToFrame), here we can use torch and torchvision transforms\n",
    "* Step5: warp the dataset using dataloader, but be aware of collate_fn, where we need to pad the frame to the same length\n",
    "* Step6: check if the result has shape [time, batch, channel, height, width] according to argument 'batch_first' in collate_fn, make sure we have time-first dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "array([(10, 30,    937, 1), (33, 20,   1030, 1), (12, 27,   1052, 1), ...,\n       ( 7, 15, 302706, 1), (26, 11, 303852, 1), (11, 17, 305341, 1)],\n      dtype=[('x', '<i8'), ('y', '<i8'), ('t', '<i8'), ('p', '<i8')])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import tonic\n",
    "\n",
    "# download the dataset from tonic\n",
    "dataset = tonic.datasets.NMNIST(save_to='/home/zxh/data', train=True)\n",
    "events, target = dataset[0]\n",
    "events"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tonic.transforms as transforms\n",
    "\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "# remove isolated events\n",
    "# sum a period of events into a frame\n",
    "frame_transform = transforms.Compose([\n",
    "    transforms.Denoise(filter_time=10000),\n",
    "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000),\n",
    "])\n",
    "trainset = tonic.datasets.NMNIST(save_to='/home/zxh/data', train=True, transform=frame_transform)\n",
    "testset = tonic.datasets.NMNIST(save_to='/home/zxh/data', train=False, transform=frame_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 310, 2, 34, 34])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "# then load the dataset the cache to accelerate data loading\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./data/cache')\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./data/cache')\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(cached_trainset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=tonic.collation.PadTensors())\n",
    "test_loader = DataLoader(cached_testset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=tonic.collation.PadTensors())\n",
    "\n",
    "# check the shape of input\n",
    "next(iter(train_loader))[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([311, 128, 2, 34, 34])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import functools\n",
    "\n",
    "transform = tonic.transforms.Compose([\n",
    "    torch.from_numpy,\n",
    "    torchvision.transforms.RandomRotation([-10,10]),\n",
    "])\n",
    "\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./data/cache', transform=transform)\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./data/cache',)\n",
    "\n",
    "# here, we need to pad the frame to the same length by using collate_fn\n",
    "# we then make time-first dataset by setting batch_first=False\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(cached_trainset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "test_loader = DataLoader(cached_testset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4,\n",
    "                        collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "\n",
    "# check the shape of input\n",
    "next(iter(train_loader))[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# define the network\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as F\n",
    "from snntorch import spikeplot as splt\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([12, 2, 5, 5]) Parameter containing:\n",
      "tensor([[[[-1.1180e-01, -1.0005e-01, -9.0381e-02, -2.5494e-02, -2.7942e-03],\n",
      "          [ 1.1488e-01, -1.2955e-01, -1.2877e-01,  5.0422e-02, -8.8030e-02],\n",
      "          [-2.5991e-02,  9.0697e-02, -1.2391e-01,  1.1566e-01, -1.3952e-01],\n",
      "          [-1.0979e-01,  1.3454e-01,  5.5713e-02,  2.1781e-02, -1.0462e-01],\n",
      "          [-5.0318e-02, -1.1123e-01,  6.9110e-02,  1.3261e-01,  1.1905e-01]],\n",
      "\n",
      "         [[-7.5508e-02,  1.3944e-01,  1.1810e-01,  4.8853e-02, -5.3461e-02],\n",
      "          [-1.3399e-01, -4.5730e-02,  1.3691e-01,  4.0151e-02, -7.8457e-02],\n",
      "          [ 9.6614e-02, -1.2718e-01,  1.4072e-01,  8.3308e-02, -1.2535e-01],\n",
      "          [-7.5135e-02,  1.5689e-02,  3.8318e-02,  1.0672e-01, -3.4452e-03],\n",
      "          [-1.3644e-01, -1.6286e-02, -2.0413e-02,  1.4026e-02, -2.1932e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4221e-03,  9.4286e-03,  1.1512e-02, -5.7152e-02,  1.2024e-01],\n",
      "          [-3.6157e-03,  8.4676e-02,  4.1033e-02, -1.5265e-02,  2.7865e-02],\n",
      "          [-6.4252e-02,  9.9379e-02,  5.1271e-02,  5.9659e-03, -2.4663e-02],\n",
      "          [ 6.1081e-02, -9.0333e-02, -1.1668e-01,  1.2204e-01, -5.0271e-02],\n",
      "          [ 1.2388e-01,  1.1466e-01,  7.9620e-02,  1.0642e-01,  1.1307e-02]],\n",
      "\n",
      "         [[-3.7461e-02,  8.5469e-02, -3.2581e-02,  4.0842e-02, -5.5464e-02],\n",
      "          [-4.4438e-03,  8.7697e-02, -8.5930e-02, -6.4850e-02, -9.6116e-03],\n",
      "          [ 4.2231e-02, -2.1851e-02,  8.1249e-02,  8.9678e-02, -7.4281e-02],\n",
      "          [-2.4801e-02, -7.4740e-02,  1.3660e-01,  1.3597e-01,  5.9700e-02],\n",
      "          [ 9.1013e-02, -9.6772e-02, -7.2784e-02,  7.8449e-02, -8.9777e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9759e-02,  1.3355e-01,  1.1586e-01, -8.3120e-02, -7.2370e-02],\n",
      "          [-1.3182e-01, -1.1617e-02, -9.2579e-02,  1.3182e-01, -1.2236e-01],\n",
      "          [-2.3840e-02,  7.3023e-02,  4.4956e-02,  7.1617e-02,  5.2158e-02],\n",
      "          [ 7.6236e-02, -3.1379e-02,  7.0301e-02, -4.5766e-02,  4.3753e-02],\n",
      "          [-9.1821e-03, -1.0271e-01,  9.2469e-02,  1.5653e-03, -1.1793e-02]],\n",
      "\n",
      "         [[ 1.1706e-01,  5.2746e-02,  1.0223e-01, -1.2112e-01,  1.6792e-02],\n",
      "          [ 1.1855e-01, -9.8641e-02,  1.0295e-01, -4.2579e-02, -4.9918e-02],\n",
      "          [ 5.2134e-02,  8.3055e-02, -1.3345e-01,  8.9076e-02, -1.3861e-01],\n",
      "          [ 4.5925e-02,  4.7696e-02, -1.3336e-01,  3.1396e-03, -5.2896e-02],\n",
      "          [ 6.7166e-02,  6.6086e-02, -1.3529e-01, -7.7950e-03, -4.9815e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3523e-02,  3.4994e-02, -7.3685e-02,  3.6305e-02,  1.3157e-02],\n",
      "          [ 8.1700e-02, -2.6351e-02,  3.0023e-03,  1.4723e-02,  9.7026e-02],\n",
      "          [-1.1160e-01,  1.3200e-01, -1.8501e-03,  1.1395e-02,  1.8203e-02],\n",
      "          [-7.0079e-02, -5.6445e-02, -3.8613e-03,  4.0340e-02,  7.2375e-02],\n",
      "          [ 1.3728e-01,  2.3888e-02, -8.4457e-02,  7.6917e-02, -1.2476e-01]],\n",
      "\n",
      "         [[ 5.2054e-02,  6.0955e-02, -1.0495e-01,  6.5919e-02,  5.9688e-02],\n",
      "          [ 4.4566e-02, -2.1922e-02, -1.2772e-01,  5.6180e-02,  1.3718e-01],\n",
      "          [-1.2795e-01,  6.9289e-02,  6.0844e-02, -4.4501e-02, -5.1266e-03],\n",
      "          [ 5.3138e-02,  3.1456e-02, -6.3985e-02,  1.3260e-01,  3.9814e-02],\n",
      "          [ 1.3885e-01, -9.8957e-02, -6.5433e-02, -5.0948e-02,  9.8379e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2479e-02,  2.2453e-02, -2.3979e-02,  7.0564e-02,  2.4438e-02],\n",
      "          [-3.7733e-02,  1.3222e-01,  3.2517e-02, -3.2256e-02,  6.9323e-02],\n",
      "          [-9.2229e-02,  2.6420e-02,  1.0762e-01, -4.3974e-02, -1.3251e-01],\n",
      "          [ 3.6265e-02, -7.2661e-02, -6.7445e-02, -1.5841e-02,  3.9514e-02],\n",
      "          [ 9.4141e-02,  1.3953e-01, -8.8994e-02, -1.0056e-01, -9.1874e-02]],\n",
      "\n",
      "         [[ 1.3344e-01, -1.5786e-02, -6.7141e-02, -3.7821e-02,  4.6743e-03],\n",
      "          [ 3.9499e-03,  6.9223e-03,  8.6716e-03, -1.2082e-01,  8.8272e-02],\n",
      "          [ 1.0084e-02, -8.9874e-02,  1.0389e-01, -1.3454e-01, -1.3333e-01],\n",
      "          [-3.8207e-03,  9.5945e-02,  8.1319e-03, -9.1100e-02,  8.5631e-02],\n",
      "          [-5.3907e-02,  4.5617e-02, -1.5395e-02, -5.0281e-02,  7.0725e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6310e-02, -3.6618e-02,  1.3164e-01, -4.4625e-02,  5.1046e-02],\n",
      "          [-8.9635e-02,  1.2162e-01, -1.0478e-01,  1.0054e-01,  5.8613e-02],\n",
      "          [ 1.0420e-01,  1.1586e-01,  1.3073e-01,  7.4539e-03, -1.3315e-01],\n",
      "          [ 4.3901e-03,  1.2864e-01,  5.1252e-02,  1.0639e-01,  1.0193e-01],\n",
      "          [-1.8174e-02, -4.8000e-02,  1.2557e-01,  1.1220e-01, -1.1626e-01]],\n",
      "\n",
      "         [[ 6.5275e-02,  8.4689e-02, -9.3285e-02, -1.4792e-02,  1.3521e-01],\n",
      "          [-1.8571e-03,  2.9976e-02,  6.4576e-02, -7.2562e-02, -8.3956e-02],\n",
      "          [ 1.0962e-01, -1.4007e-01, -1.1725e-01,  8.3447e-02,  1.0172e-01],\n",
      "          [ 1.2310e-01,  6.4385e-02, -6.1814e-02,  1.1275e-01,  4.6448e-02],\n",
      "          [ 1.1680e-02,  6.8942e-03,  3.7646e-02, -6.3923e-02,  3.4587e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3282e-05,  1.3205e-01,  1.1873e-02, -7.9250e-02,  1.0572e-01],\n",
      "          [ 9.9215e-02, -6.9162e-02,  1.1416e-02, -4.4953e-02,  1.0829e-01],\n",
      "          [ 1.2440e-01,  2.8691e-02, -8.9898e-02, -3.4654e-02,  1.1695e-01],\n",
      "          [ 9.1428e-02,  2.0985e-02,  8.0862e-02, -5.1126e-02, -3.4286e-02],\n",
      "          [ 8.0653e-02,  2.4903e-02,  7.7763e-02,  1.3921e-01, -7.3391e-02]],\n",
      "\n",
      "         [[ 1.2209e-02, -2.8654e-02,  5.1875e-02, -5.7506e-02, -7.8510e-02],\n",
      "          [ 1.2326e-01, -7.7872e-02, -1.9904e-02, -4.5302e-02, -9.6187e-02],\n",
      "          [ 6.8529e-02,  7.4233e-02,  5.7569e-02, -1.6089e-02, -1.1848e-02],\n",
      "          [ 3.5769e-02,  7.9282e-02,  5.8697e-02,  7.3200e-02, -5.0825e-02],\n",
      "          [-3.7922e-02,  8.6838e-02,  7.1439e-02, -1.1666e-01, -2.6382e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1542e-02, -1.0161e-01, -1.2989e-01, -1.3442e-01,  4.6646e-03],\n",
      "          [-3.0561e-02,  1.3625e-01,  4.9850e-02,  9.5101e-03,  4.1660e-02],\n",
      "          [ 9.3312e-02,  6.6225e-02, -7.1845e-02,  4.6343e-02,  3.9849e-02],\n",
      "          [-1.3413e-02,  9.1206e-05, -1.1853e-01, -1.0441e-01,  1.1291e-01],\n",
      "          [-5.7893e-03, -1.1915e-01, -3.1792e-04,  1.3734e-01,  5.6001e-02]],\n",
      "\n",
      "         [[ 2.7055e-02, -1.1195e-01, -1.0513e-01,  1.0933e-01, -1.7201e-02],\n",
      "          [-1.2766e-02,  7.6551e-02,  1.1731e-01, -1.4955e-02,  4.1990e-03],\n",
      "          [ 2.0345e-02, -7.5185e-02,  9.2653e-02, -1.1296e-01,  8.6709e-02],\n",
      "          [-2.1002e-02, -1.3338e-01,  1.3093e-01, -9.0797e-02, -1.1641e-02],\n",
      "          [ 2.4587e-02, -3.9533e-02, -5.8173e-03, -1.3634e-01,  4.5831e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3239e-02,  6.0458e-02,  9.9144e-02,  3.2752e-02,  8.4330e-02],\n",
      "          [-1.2153e-01,  1.0045e-01,  1.3660e-01, -5.0581e-02, -6.8468e-02],\n",
      "          [ 6.6042e-02, -1.5478e-02,  1.2726e-01, -6.1752e-02, -5.7027e-02],\n",
      "          [ 6.9736e-02,  6.8870e-02, -1.4089e-01,  2.0830e-03, -1.1838e-01],\n",
      "          [-5.2672e-02,  1.1223e-01, -4.9455e-02,  4.4051e-02, -3.3993e-02]],\n",
      "\n",
      "         [[ 4.3744e-02, -5.6610e-02,  1.2930e-01, -9.1009e-02,  1.9025e-02],\n",
      "          [-4.7720e-02,  1.2036e-01,  1.3824e-01,  7.3521e-02,  5.8677e-02],\n",
      "          [ 1.1019e-01,  6.5892e-02,  1.6052e-02,  7.9711e-02,  4.9821e-02],\n",
      "          [ 3.4128e-02, -1.1848e-01, -8.5436e-02,  1.1512e-01, -7.1314e-02],\n",
      "          [-1.0809e-02,  5.3586e-02, -1.3959e-01,  6.4131e-02, -8.4568e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5674e-02,  6.6563e-03, -1.1607e-01,  1.1643e-01,  1.2140e-01],\n",
      "          [ 1.2004e-01, -3.5150e-02, -7.1974e-02,  9.8928e-02, -6.6427e-02],\n",
      "          [-7.5680e-02, -9.9267e-02,  3.4981e-02, -1.3733e-01, -1.1680e-01],\n",
      "          [ 5.7434e-02, -3.3921e-02, -8.5050e-02, -1.9305e-02,  4.8378e-02],\n",
      "          [-6.1843e-03,  3.8622e-02, -1.4270e-02, -1.5745e-02, -1.5341e-02]],\n",
      "\n",
      "         [[-9.7463e-02,  2.0764e-02, -7.7818e-02, -1.1164e-01,  8.0094e-02],\n",
      "          [ 2.4739e-02, -1.0106e-01,  7.5959e-02, -1.0164e-01,  5.3488e-02],\n",
      "          [-1.3619e-01, -8.6305e-02,  6.6116e-02,  3.6166e-03,  1.6100e-02],\n",
      "          [-2.0541e-02,  9.1042e-03,  9.2154e-02,  1.1078e-01, -1.2201e-01],\n",
      "          [-7.5513e-02, -1.0042e-01,  3.8749e-02, -3.4617e-02,  8.1514e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0232e-02, -1.4096e-01, -2.1639e-02, -8.7846e-02, -1.3438e-01],\n",
      "          [ 1.3203e-02, -5.4441e-02, -1.0551e-02,  8.9618e-03,  6.8509e-02],\n",
      "          [ 1.1711e-01, -1.3772e-01, -4.3023e-02,  5.0586e-02, -1.2865e-01],\n",
      "          [-1.0463e-01, -3.6636e-02,  6.4810e-02,  1.3218e-02,  8.5772e-02],\n",
      "          [-4.6839e-02, -1.4075e-01,  3.7421e-03, -4.0045e-02,  5.1267e-03]],\n",
      "\n",
      "         [[-7.6867e-02, -4.5172e-02, -1.1550e-01,  1.1588e-02, -1.5837e-02],\n",
      "          [-4.9496e-03,  1.1120e-01, -1.0810e-01, -4.8031e-02, -4.2846e-02],\n",
      "          [-1.1903e-01,  3.1300e-02, -8.3125e-02, -1.2204e-01, -1.2105e-01],\n",
      "          [-1.0078e-01, -1.2542e-02, -1.6760e-02,  5.6128e-02, -8.7250e-02],\n",
      "          [-2.6905e-02,  8.1149e-02,  9.8369e-02, -7.7301e-02, -1.3506e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8905e-02, -6.0101e-04, -2.2159e-02,  4.4476e-02, -2.1327e-02],\n",
      "          [ 5.4642e-02,  9.6903e-03,  1.1376e-01, -2.7599e-02, -3.0405e-02],\n",
      "          [ 7.9895e-02,  7.9803e-02,  6.1612e-02, -2.4406e-02, -7.3550e-03],\n",
      "          [ 1.2586e-01, -3.7146e-02, -9.4801e-02,  7.9927e-02, -9.0932e-02],\n",
      "          [-9.4040e-02, -5.7441e-02, -7.0024e-02, -7.5351e-02, -9.0238e-02]],\n",
      "\n",
      "         [[-4.2501e-02,  1.1055e-01,  9.1506e-02,  1.0598e-01,  1.3273e-01],\n",
      "          [-2.4596e-02,  7.6186e-02,  9.7658e-02, -1.0263e-01, -5.7674e-05],\n",
      "          [-1.3976e-01, -6.8869e-02,  8.3728e-02,  1.3557e-01,  5.6065e-02],\n",
      "          [ 5.2270e-02,  8.0364e-02,  4.5959e-02,  1.8265e-02, -1.8037e-02],\n",
      "          [-1.0266e-01,  1.3096e-01,  1.2390e-01, -1.0316e-02,  4.5781e-02]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "conv1.bias torch.Size([12]) Parameter containing:\n",
      "tensor([ 0.0087, -0.0397,  0.0474,  0.1155,  0.0273,  0.0315, -0.0459,  0.0789,\n",
      "        -0.0657, -0.0944, -0.1042,  0.1157], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "conv2.weight torch.Size([32, 12, 5, 5]) Parameter containing:\n",
      "tensor([[[[-1.9921e-04,  4.7261e-03, -5.0612e-02,  5.7276e-02, -1.9386e-02],\n",
      "          [ 4.2549e-02,  5.2836e-02,  1.3352e-02, -3.0796e-02,  5.6432e-02],\n",
      "          [-5.6821e-02,  5.3199e-03,  3.6676e-02, -3.9260e-02, -4.5225e-02],\n",
      "          [ 1.2588e-02,  4.6830e-02, -3.7369e-02,  2.2401e-02, -2.8479e-02],\n",
      "          [ 2.0891e-04,  4.6805e-02,  1.3215e-04, -5.5102e-02, -4.9251e-02]],\n",
      "\n",
      "         [[-7.3381e-03,  5.7625e-02, -1.9606e-02, -3.7771e-02,  1.7206e-02],\n",
      "          [ 2.2239e-02,  1.0499e-02,  2.3865e-02,  4.4147e-02,  3.1124e-02],\n",
      "          [ 6.9007e-03, -8.1804e-03,  5.2225e-02,  2.9607e-02,  2.4390e-02],\n",
      "          [-5.3178e-02, -3.7707e-04,  4.8985e-02, -3.0487e-02,  1.5083e-02],\n",
      "          [ 1.9785e-02,  2.3429e-02, -2.7511e-02,  2.3440e-02,  4.5091e-02]],\n",
      "\n",
      "         [[-4.8858e-02,  5.6300e-02,  2.5086e-02,  3.7682e-02,  4.2427e-02],\n",
      "          [ 5.2372e-02, -4.2178e-02, -3.5557e-02,  2.5953e-02,  3.9068e-02],\n",
      "          [-4.6889e-02, -1.7438e-02, -2.9424e-02,  1.6557e-02, -3.6323e-02],\n",
      "          [-3.6643e-02, -5.3525e-02,  3.8390e-02,  2.8205e-02,  2.3951e-02],\n",
      "          [ 2.5017e-02,  2.7316e-02,  3.0874e-02,  1.7267e-02,  5.5998e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5099e-02,  3.5013e-02, -3.6828e-02, -4.5289e-02,  2.1311e-02],\n",
      "          [-2.0084e-02, -2.4740e-02, -1.3086e-02, -5.4473e-02,  3.5750e-02],\n",
      "          [ 3.8626e-02,  3.7483e-02, -4.1630e-02, -2.5459e-03, -1.6815e-02],\n",
      "          [ 1.6286e-02,  1.7329e-03,  1.5172e-02,  5.7257e-02,  4.6847e-02],\n",
      "          [-5.4307e-02,  5.2657e-02,  4.6984e-02, -4.5520e-02,  5.0720e-02]],\n",
      "\n",
      "         [[ 1.5570e-02, -1.0639e-02,  1.2704e-02, -2.0319e-03, -1.4036e-02],\n",
      "          [ 2.5417e-02, -2.5839e-02,  1.7883e-02, -4.1692e-02,  2.7785e-02],\n",
      "          [-5.4600e-02, -1.2092e-02,  2.0431e-02, -1.1675e-02, -2.7087e-02],\n",
      "          [-4.5588e-02, -2.1095e-02,  3.8142e-02, -2.9955e-02,  1.6567e-02],\n",
      "          [ 5.4907e-02,  2.8752e-02, -3.3138e-02, -3.2546e-02,  1.9289e-02]],\n",
      "\n",
      "         [[ 4.7471e-02,  4.3052e-02,  3.8705e-03,  5.2881e-02,  1.7390e-02],\n",
      "          [ 6.7279e-04, -5.1802e-02, -2.7324e-02, -2.0906e-02, -3.2519e-02],\n",
      "          [-3.1584e-02,  1.2053e-02, -3.5933e-02,  4.7952e-02, -5.5526e-02],\n",
      "          [ 4.3407e-02,  5.4588e-02,  4.4286e-03, -4.7227e-02, -3.1468e-02],\n",
      "          [ 2.1871e-03,  4.5648e-02,  9.2788e-04, -5.5649e-02, -4.9090e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7912e-03, -5.5995e-02, -1.8795e-02,  2.4896e-02, -4.2920e-03],\n",
      "          [-2.6348e-02,  3.8767e-02, -1.3465e-03,  4.7721e-02,  2.5721e-02],\n",
      "          [ 3.6806e-02, -4.4027e-02,  7.1068e-03, -4.9148e-02,  2.2088e-02],\n",
      "          [ 1.5402e-02, -5.1698e-02,  1.6603e-02, -5.6132e-02, -1.0689e-02],\n",
      "          [ 2.9002e-02, -5.2529e-02,  4.2732e-02, -5.7051e-02, -4.1430e-02]],\n",
      "\n",
      "         [[ 3.3776e-02, -2.3041e-03, -3.7464e-02, -1.5775e-02, -3.0355e-02],\n",
      "          [ 2.0167e-02,  1.3246e-02, -1.9995e-02,  5.2815e-02, -2.9319e-02],\n",
      "          [-1.4999e-02,  1.6388e-02, -3.1699e-02,  3.6935e-02, -5.0797e-02],\n",
      "          [-3.1619e-02,  3.8230e-02, -2.3517e-02, -4.3443e-02,  4.2740e-03],\n",
      "          [-2.2823e-03, -1.2017e-02, -2.2123e-02,  1.5210e-02,  4.9660e-02]],\n",
      "\n",
      "         [[-4.3330e-03, -5.6022e-02,  4.1178e-02,  2.4707e-02, -1.5355e-02],\n",
      "          [-5.3793e-02, -4.4451e-02, -2.5994e-02,  5.0378e-02, -2.6197e-02],\n",
      "          [-4.8455e-02, -2.6537e-02, -3.6346e-02,  9.4539e-03,  3.0869e-02],\n",
      "          [ 1.8134e-02,  2.8952e-02,  1.5099e-02, -3.0602e-02, -5.3522e-02],\n",
      "          [-5.1585e-02,  5.6728e-02, -1.3267e-02, -3.3079e-02, -2.1889e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4865e-02,  5.4611e-02,  3.4368e-02,  3.1694e-02,  3.7144e-02],\n",
      "          [-3.7053e-02,  4.6026e-02,  4.6640e-02, -6.1197e-03,  1.0411e-02],\n",
      "          [-2.9143e-02, -2.7873e-02,  8.8714e-03, -2.7339e-02,  5.4062e-02],\n",
      "          [-4.2473e-02, -8.7952e-03, -3.0273e-02,  1.6599e-02, -3.2462e-02],\n",
      "          [-4.5405e-02,  1.4439e-02, -3.4715e-02, -4.7666e-03,  4.1042e-03]],\n",
      "\n",
      "         [[-3.1682e-02,  3.1069e-02,  5.1048e-02,  1.9727e-02,  2.5888e-02],\n",
      "          [ 2.5740e-02, -3.9195e-02, -5.4086e-02,  3.7847e-02,  1.3458e-02],\n",
      "          [-2.3714e-04,  3.7016e-03,  4.1149e-02, -2.9604e-02,  1.8248e-02],\n",
      "          [-4.3375e-02,  4.2498e-02, -5.5139e-02,  2.4390e-02,  7.1296e-03],\n",
      "          [ 4.7954e-02, -2.2047e-03, -2.2952e-02,  3.8824e-02,  3.5449e-02]],\n",
      "\n",
      "         [[ 5.7246e-02, -1.6326e-02, -4.1201e-02, -1.4025e-02,  4.6921e-02],\n",
      "          [ 3.4243e-02,  4.3934e-02, -9.2861e-03, -3.5352e-02,  4.2517e-02],\n",
      "          [ 8.4200e-03,  4.5420e-03,  1.5602e-03,  3.4299e-02, -2.8639e-02],\n",
      "          [-2.0240e-02, -3.9345e-02,  3.7320e-02, -4.2784e-02, -1.2763e-02],\n",
      "          [ 3.0819e-03, -5.3145e-02, -3.2628e-02,  1.8829e-02,  2.6769e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2121e-02, -1.9857e-02, -5.1567e-02, -2.2813e-02,  4.3854e-04],\n",
      "          [ 3.4507e-03,  5.7096e-03, -1.0400e-02,  4.2458e-02, -3.3291e-02],\n",
      "          [ 2.2653e-02,  1.2880e-02, -2.4663e-02, -3.4815e-02, -2.0894e-02],\n",
      "          [-1.9725e-02,  3.5607e-04, -1.7755e-02, -5.3270e-02, -2.5848e-02],\n",
      "          [-2.0742e-02, -4.6982e-02,  2.7475e-02, -4.9267e-02, -2.8587e-02]],\n",
      "\n",
      "         [[ 4.2598e-02, -3.9329e-02,  5.1548e-03, -3.3248e-02,  5.3237e-02],\n",
      "          [ 2.0044e-02,  3.8920e-02, -2.1975e-02, -4.8647e-02,  4.8097e-02],\n",
      "          [-5.0893e-02,  1.5935e-03,  3.8147e-02,  1.8328e-02,  3.5298e-02],\n",
      "          [ 1.1189e-02,  2.2005e-02, -1.5536e-02, -4.3569e-03,  2.7208e-02],\n",
      "          [ 2.8504e-02,  3.2964e-02, -4.5137e-02,  4.9893e-02,  4.9837e-03]],\n",
      "\n",
      "         [[ 5.0885e-03,  4.8993e-02, -1.6265e-03, -5.6486e-02,  1.3228e-02],\n",
      "          [-5.8190e-03, -4.5523e-02, -4.5551e-02,  1.2991e-02,  4.1790e-02],\n",
      "          [ 2.0807e-02, -1.4835e-02, -1.9119e-02, -3.7298e-02,  4.8176e-02],\n",
      "          [-1.0494e-02,  4.5858e-02, -3.2868e-02,  2.8947e-02,  2.4323e-02],\n",
      "          [ 3.5256e-02, -3.3976e-02,  2.3269e-02,  4.4683e-02, -3.5342e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1916e-02, -2.7806e-03, -1.2878e-02, -1.1019e-02,  3.2986e-03],\n",
      "          [ 2.6963e-02, -1.0387e-02,  1.2145e-02, -2.9646e-02,  4.3947e-02],\n",
      "          [-2.8904e-02, -3.2930e-02,  5.5668e-02,  2.5355e-02, -2.0637e-02],\n",
      "          [ 5.7148e-02,  2.8473e-02, -2.8244e-02,  5.7014e-02,  2.0093e-02],\n",
      "          [-3.8426e-02, -1.6962e-02,  1.6421e-03, -5.7640e-02,  3.3473e-02]],\n",
      "\n",
      "         [[-4.9410e-02, -3.1122e-02, -5.2068e-02, -1.1490e-02, -1.3129e-03],\n",
      "          [-1.8015e-02,  3.8270e-03,  4.9885e-02, -1.3060e-02,  3.3159e-02],\n",
      "          [ 3.5013e-02, -5.1317e-02,  8.3046e-03,  1.3307e-02, -3.2128e-02],\n",
      "          [-1.0131e-02, -3.8699e-02, -7.5494e-03,  1.5698e-02, -3.6437e-02],\n",
      "          [-4.2751e-02,  1.7516e-02, -3.4780e-02, -5.1323e-02, -8.9811e-03]],\n",
      "\n",
      "         [[-4.8776e-02,  2.3395e-02,  4.0609e-02, -1.1687e-02, -3.0639e-02],\n",
      "          [ 3.9010e-03,  3.0911e-02, -5.2070e-02, -3.3233e-02,  6.0787e-03],\n",
      "          [ 5.3182e-02, -5.1513e-02,  4.4507e-02, -1.3993e-02,  4.5752e-02],\n",
      "          [-5.2389e-02, -4.3496e-02, -4.2595e-02, -3.4655e-02,  5.6582e-03],\n",
      "          [ 5.1363e-02,  7.0399e-03, -1.3434e-02, -1.3347e-02, -2.8944e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.5900e-03, -5.1218e-02, -5.7612e-02,  1.8681e-03,  9.7471e-05],\n",
      "          [-9.2912e-03,  3.5853e-02, -6.3290e-03,  4.4670e-02,  6.4806e-03],\n",
      "          [-3.8341e-02,  2.3794e-02, -3.4353e-02,  4.1511e-02, -5.6845e-02],\n",
      "          [ 4.7394e-02, -4.3326e-03,  3.2253e-02,  1.1330e-03, -3.2784e-02],\n",
      "          [ 5.6913e-02,  4.4367e-02,  3.8676e-02, -1.8014e-02, -4.5843e-02]],\n",
      "\n",
      "         [[ 4.8104e-02,  3.8999e-02,  3.5466e-02, -1.7142e-02,  5.5877e-02],\n",
      "          [-4.5805e-02,  3.8862e-03, -3.8031e-02,  3.4669e-02,  4.7682e-02],\n",
      "          [-1.0465e-02, -4.1223e-02,  3.5156e-02,  3.0279e-02,  5.2325e-02],\n",
      "          [ 4.9437e-02, -3.1207e-02,  2.6466e-02,  2.8866e-02, -1.5874e-02],\n",
      "          [-4.0255e-02, -2.6178e-02,  1.9355e-02,  4.8751e-02, -5.3519e-02]],\n",
      "\n",
      "         [[-3.9855e-02, -2.4430e-02,  3.3800e-02,  7.6430e-04,  5.6064e-02],\n",
      "          [ 3.0505e-02,  1.0434e-02,  5.5515e-02, -5.4322e-02, -4.8114e-02],\n",
      "          [-2.7719e-02, -1.6621e-02,  1.3877e-02,  1.4692e-03, -5.2051e-02],\n",
      "          [-1.4856e-02,  2.1628e-02,  2.6884e-02, -2.5884e-02, -2.0354e-02],\n",
      "          [ 5.3715e-02, -1.1442e-02, -3.9702e-02, -3.1535e-02, -1.2508e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0906e-02, -2.8089e-02, -3.8763e-02,  1.5793e-02,  2.0274e-02],\n",
      "          [-5.2567e-02, -4.1215e-02, -3.3802e-02,  2.8790e-03,  4.3680e-02],\n",
      "          [-3.9336e-02, -2.3141e-02, -4.3518e-02, -1.8962e-02,  1.3604e-02],\n",
      "          [ 5.1400e-02, -4.8709e-03, -3.2827e-02,  4.2204e-02,  4.8481e-02],\n",
      "          [-5.1006e-02, -1.5441e-02,  6.6401e-03, -1.2445e-02, -3.1176e-02]],\n",
      "\n",
      "         [[ 5.5358e-02,  3.5116e-02, -4.8773e-02, -4.2604e-02,  1.3907e-02],\n",
      "          [-1.1856e-02, -6.6200e-03, -9.6252e-03, -3.9517e-02,  4.7581e-02],\n",
      "          [-9.2081e-03,  2.6232e-02, -1.6027e-02,  2.2354e-02, -4.7844e-02],\n",
      "          [-1.3528e-02, -4.2694e-03,  5.0730e-02,  6.9433e-03,  3.0685e-02],\n",
      "          [-3.8855e-02,  2.3503e-02,  4.1866e-02,  3.9267e-02,  4.1725e-02]],\n",
      "\n",
      "         [[-4.4941e-02, -3.1395e-02,  5.0574e-02,  4.8134e-02, -3.3428e-02],\n",
      "          [-1.6980e-02,  1.3757e-02,  5.9746e-03, -1.6201e-02,  1.0581e-02],\n",
      "          [-1.7431e-02, -2.3252e-02, -2.6522e-02, -1.6894e-02,  4.2293e-02],\n",
      "          [-7.2191e-03,  2.9570e-02, -1.8550e-02, -1.7411e-02, -3.5461e-02],\n",
      "          [ 2.4804e-02,  4.1016e-02, -1.7811e-04, -3.1565e-02,  5.1171e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7649e-02, -3.5571e-02,  3.8783e-02,  1.0414e-02,  3.5402e-02],\n",
      "          [-4.5411e-02,  4.0181e-02,  3.3389e-02,  4.7316e-02, -2.7091e-02],\n",
      "          [ 5.0074e-02,  4.2794e-02,  3.2758e-02, -1.4389e-03, -3.3532e-02],\n",
      "          [ 7.9962e-03, -3.1531e-02,  4.3424e-02, -4.5971e-02,  4.8511e-03],\n",
      "          [ 2.9489e-02, -5.7000e-02, -1.8916e-02,  4.9245e-02, -4.9975e-02]],\n",
      "\n",
      "         [[ 2.6411e-02, -1.6750e-02,  7.3916e-03,  3.4013e-02,  1.9600e-02],\n",
      "          [ 5.6890e-02,  2.5148e-02,  4.8018e-02, -4.0698e-02, -5.0556e-02],\n",
      "          [-5.5618e-02, -2.7653e-02,  2.0362e-02,  5.6909e-03,  3.3409e-02],\n",
      "          [ 2.1299e-02,  5.3160e-02, -3.8040e-05,  2.6573e-03, -3.8224e-03],\n",
      "          [-3.7834e-02,  4.0014e-02, -3.8732e-02, -4.2108e-03, -2.5591e-02]],\n",
      "\n",
      "         [[ 2.6426e-02, -5.0169e-02,  5.6554e-02, -4.3387e-02,  7.2104e-03],\n",
      "          [-1.7983e-02, -4.7137e-02,  2.1546e-03, -1.4672e-02, -2.8611e-05],\n",
      "          [-3.2737e-02, -1.5944e-02,  4.1765e-03,  1.3811e-04,  4.3253e-02],\n",
      "          [ 3.8821e-02, -2.0860e-02, -2.8703e-02,  4.0876e-02, -4.6699e-02],\n",
      "          [ 1.9514e-02, -2.3936e-02,  4.6616e-02, -4.7557e-02,  4.0155e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3434e-02, -4.9315e-02,  8.5167e-03,  5.1075e-03, -1.6255e-02],\n",
      "          [ 9.2187e-03, -1.3099e-02,  7.5041e-03,  3.8570e-02,  1.4901e-02],\n",
      "          [ 2.4772e-02,  3.7209e-02, -1.5402e-03, -2.7762e-02,  3.6596e-02],\n",
      "          [ 9.2174e-03, -4.5981e-02, -1.3364e-02, -3.1126e-02, -5.5264e-02],\n",
      "          [ 5.3418e-02,  3.0052e-02,  2.4488e-02, -4.7960e-02,  2.9955e-02]],\n",
      "\n",
      "         [[ 1.5059e-02,  4.6314e-02,  4.9245e-02,  4.1114e-02,  4.3189e-02],\n",
      "          [ 4.0510e-02, -8.4536e-03,  4.8374e-02,  6.7677e-03, -1.1314e-02],\n",
      "          [-6.4467e-03, -5.9689e-04,  9.9286e-03,  2.2203e-02, -1.5306e-02],\n",
      "          [-1.6114e-02, -4.3108e-02,  7.4038e-03, -2.6883e-03,  4.8070e-02],\n",
      "          [-5.1958e-02, -1.3939e-02,  2.0311e-02, -2.1654e-02,  2.2954e-02]],\n",
      "\n",
      "         [[-2.7647e-02, -4.2991e-03,  1.3146e-02,  4.2455e-03, -5.5432e-02],\n",
      "          [-1.2548e-03, -1.7289e-02,  3.9254e-02, -1.7001e-02, -5.5964e-03],\n",
      "          [ 2.8854e-03,  2.1124e-02,  4.2644e-02, -3.7921e-02, -5.2094e-02],\n",
      "          [ 5.0207e-02,  9.5768e-03,  4.7703e-02,  1.6569e-02,  1.2366e-02],\n",
      "          [-5.1379e-02, -1.4626e-02,  5.3154e-02,  2.4545e-02, -2.5175e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3140e-02, -4.1737e-02,  1.7599e-03,  1.0840e-02, -1.1411e-02],\n",
      "          [ 5.3721e-02, -5.4608e-02, -3.8190e-02,  3.8567e-02,  1.0593e-02],\n",
      "          [-3.1181e-02, -3.8594e-02,  3.7481e-02, -4.5315e-02, -3.1731e-02],\n",
      "          [-5.2668e-02, -5.1579e-02, -2.7128e-02, -5.0822e-02, -4.9375e-02],\n",
      "          [-1.4026e-02, -2.5961e-02,  2.9280e-02, -3.7075e-02, -3.7415e-02]],\n",
      "\n",
      "         [[ 1.7418e-02,  3.3459e-04, -1.9798e-02, -4.2819e-02, -3.0341e-02],\n",
      "          [-3.1758e-02,  5.5588e-04, -5.6934e-02,  1.4393e-02,  5.1917e-02],\n",
      "          [ 5.3864e-02,  1.7739e-02, -3.9231e-05,  1.9074e-02, -1.6484e-02],\n",
      "          [ 4.2121e-02, -4.8003e-02, -4.0414e-02, -4.2085e-02, -2.3568e-02],\n",
      "          [ 5.4567e-03, -3.6092e-02, -2.9512e-03, -5.4648e-02,  5.7637e-02]],\n",
      "\n",
      "         [[ 4.3520e-02, -3.8727e-02, -4.4083e-02,  4.4771e-02, -4.1813e-03],\n",
      "          [-5.3595e-02,  4.6809e-02, -3.2986e-03,  3.5479e-02,  3.5648e-02],\n",
      "          [ 5.1293e-02,  2.4989e-02,  4.2322e-02,  1.4744e-02,  4.0825e-02],\n",
      "          [ 6.2067e-03, -2.7276e-02, -1.8400e-02, -2.9546e-02, -3.7061e-02],\n",
      "          [ 3.2802e-02,  2.7262e-02, -4.7163e-02,  2.3251e-02,  3.4077e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2545e-02, -1.9912e-02,  2.8866e-02,  3.8070e-02, -3.4039e-02],\n",
      "          [ 1.4161e-02, -2.8972e-04, -2.7648e-02, -9.7160e-03,  4.3653e-02],\n",
      "          [-3.8582e-02, -9.7568e-03,  4.2620e-02,  7.5981e-03, -1.6078e-02],\n",
      "          [ 4.2058e-02, -4.5818e-02, -2.8148e-02, -5.0364e-02, -1.3207e-02],\n",
      "          [-3.2577e-02, -1.1413e-02,  2.6267e-02,  4.7258e-02, -3.4432e-02]],\n",
      "\n",
      "         [[ 4.9865e-02, -1.8818e-02, -2.9073e-02, -1.6880e-02,  1.0988e-02],\n",
      "          [-3.8649e-02,  8.1046e-03, -1.3046e-02,  5.5490e-02, -4.2576e-02],\n",
      "          [ 1.1007e-02,  3.0798e-02, -2.9056e-02,  2.9718e-02, -1.8449e-03],\n",
      "          [-9.5593e-03,  4.5809e-02, -3.4466e-02,  3.6882e-02,  2.5354e-03],\n",
      "          [-1.9248e-02, -2.2175e-02, -3.6723e-02,  1.5035e-02, -1.9263e-02]],\n",
      "\n",
      "         [[ 2.5661e-02, -1.9678e-02,  8.6967e-03, -1.3037e-02,  3.0482e-02],\n",
      "          [ 1.8358e-02,  4.0995e-02, -5.3949e-02, -5.1203e-02, -4.6814e-02],\n",
      "          [-4.8647e-02,  1.8311e-02, -5.7336e-02, -2.5320e-02,  2.0857e-02],\n",
      "          [-1.5444e-02, -1.1464e-02,  2.0881e-02,  8.9573e-03, -2.9615e-02],\n",
      "          [-1.8220e-02, -9.6083e-03,  4.7996e-02, -3.4140e-02,  1.5783e-02]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "conv2.bias torch.Size([32]) Parameter containing:\n",
      "tensor([-0.0140, -0.0339,  0.0148,  0.0313, -0.0385,  0.0166, -0.0213,  0.0263,\n",
      "         0.0160,  0.0226, -0.0091, -0.0490,  0.0490, -0.0163, -0.0418, -0.0201,\n",
      "         0.0361,  0.0283,  0.0175,  0.0517, -0.0025, -0.0181,  0.0005, -0.0364,\n",
      "         0.0282,  0.0266, -0.0392, -0.0201,  0.0341, -0.0505, -0.0222, -0.0301],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "linear.weight torch.Size([10, 800]) Parameter containing:\n",
      "tensor([[-0.0219,  0.0094, -0.0122,  ..., -0.0207, -0.0125, -0.0324],\n",
      "        [-0.0205, -0.0215,  0.0053,  ...,  0.0312,  0.0318, -0.0020],\n",
      "        [ 0.0012, -0.0266,  0.0169,  ..., -0.0312, -0.0239,  0.0041],\n",
      "        ...,\n",
      "        [ 0.0298, -0.0300, -0.0126,  ..., -0.0093,  0.0292,  0.0147],\n",
      "        [ 0.0288,  0.0338, -0.0216,  ...,  0.0342, -0.0002,  0.0019],\n",
      "        [ 0.0148, -0.0286,  0.0110,  ..., -0.0345,  0.0194, -0.0278]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "linear.bias torch.Size([10]) Parameter containing:\n",
      "tensor([-0.0096, -0.0162,  0.0234,  0.0216,  0.0184, -0.0046, -0.0036, -0.0148,\n",
      "        -0.0035,  0.0185], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "#  Initialize Network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 12, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.snn1 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "        self.conv2 = nn.Conv2d(12, 32, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.snn2 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(32*5*5, 10)\n",
    "        self.snn3 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.snn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.snn2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.snn3(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_sparsity(x):\n",
    "        return (x == 0).float().mean()\n",
    "\n",
    "net = SimpleNet().to(device)\n",
    "for k, v in net.named_parameters():\n",
    "    print(k, v.shape, v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-2)\n",
    "loss_fn = F.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import time\n",
    "num_epochs = 1\n",
    "num_iters = 50\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "# define the forward pass\n",
    "\n",
    "def forward(net, data):\n",
    "    spk_rec = []\n",
    "    utils.reset(net)\n",
    "\n",
    "    for step in range(data.size(0)):\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "\n",
    "    return torch.stack(spk_rec, dim=0)\n",
    "\n",
    "\n",
    "# training loop\n",
    "def train_network(net, num_epochs, acc_fn, loss_fn):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, targets) in enumerate(iter(train_loader)):\n",
    "            start = time.time()\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            net.train()\n",
    "            spk_rec = forward(net, data)\n",
    "            loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "            # Gradient calculation + weight update\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            # Store loss history for future plotting\n",
    "            loss_hist.append(loss_val.item())\n",
    "\n",
    "            print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}, time: {end-start:.2f}s\")\n",
    "\n",
    "            acc = acc_fn(spk_rec, targets)\n",
    "            acc_hist.append(acc)\n",
    "            print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "            # training loop breaks after 50 iterations\n",
    "            if i == num_iters:\n",
    "              break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0 \n",
      "Train Loss: 30.96, time: 6.61s\n",
      "Accuracy: 11.72%\n",
      "\n",
      "Epoch 0, Iteration 1 \n",
      "Train Loss: 30.90, time: 2.29s\n",
      "Accuracy: 9.38%\n",
      "\n",
      "Epoch 0, Iteration 2 \n",
      "Train Loss: 30.90, time: 2.49s\n",
      "Accuracy: 9.38%\n",
      "\n",
      "Epoch 0, Iteration 3 \n",
      "Train Loss: 24.96, time: 2.48s\n",
      "Accuracy: 10.94%\n",
      "\n",
      "Epoch 0, Iteration 4 \n",
      "Train Loss: 12.39, time: 2.48s\n",
      "Accuracy: 6.25%\n",
      "\n",
      "Epoch 0, Iteration 5 \n",
      "Train Loss: 16.74, time: 2.19s\n",
      "Accuracy: 13.28%\n",
      "\n",
      "Epoch 0, Iteration 6 \n",
      "Train Loss: 18.59, time: 2.79s\n",
      "Accuracy: 19.53%\n",
      "\n",
      "Epoch 0, Iteration 7 \n",
      "Train Loss: 17.15, time: 3.36s\n",
      "Accuracy: 18.75%\n",
      "\n",
      "Epoch 0, Iteration 8 \n",
      "Train Loss: 13.95, time: 3.33s\n",
      "Accuracy: 25.78%\n",
      "\n",
      "Epoch 0, Iteration 9 \n",
      "Train Loss: 12.50, time: 2.73s\n",
      "Accuracy: 22.66%\n",
      "\n",
      "Epoch 0, Iteration 10 \n",
      "Train Loss: 15.44, time: 2.59s\n",
      "Accuracy: 17.97%\n",
      "\n",
      "Epoch 0, Iteration 11 \n",
      "Train Loss: 14.35, time: 2.83s\n",
      "Accuracy: 26.56%\n",
      "\n",
      "Epoch 0, Iteration 12 \n",
      "Train Loss: 12.32, time: 2.69s\n",
      "Accuracy: 26.56%\n",
      "\n",
      "Epoch 0, Iteration 13 \n",
      "Train Loss: 12.45, time: 2.01s\n",
      "Accuracy: 22.66%\n",
      "\n",
      "Epoch 0, Iteration 14 \n",
      "Train Loss: 13.39, time: 2.10s\n",
      "Accuracy: 17.19%\n",
      "\n",
      "Epoch 0, Iteration 15 \n",
      "Train Loss: 13.52, time: 2.25s\n",
      "Accuracy: 28.12%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/tonic/cached_dataset.py\", line 137, in __getitem__\n    data, targets = load_from_disk_cache(file_path)\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/tonic/cached_dataset.py\", line 214, in load_from_disk_cache\n    for index in f[name].keys():\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/h5py/_hl/group.py\", line 328, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\nKeyError: \"Unable to open object (object 'target' doesn't exist)\"\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccuracy_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36mtrain_network\u001B[0;34m(net, num_epochs, acc_fn, loss_fn)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_network\u001B[39m(net, num_epochs, acc_fn, loss_fn):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m---> 25\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i, (data, targets) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28miter\u001B[39m(train_loader)):\n\u001B[1;32m     26\u001B[0m             start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     27\u001B[0m             data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    633\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 634\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    638\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1326\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rcvd_idx]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m   1325\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rcvd_idx)[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m-> 1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1372\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1372\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/_utils.py:644\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m--> 644\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mKeyError\u001B[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/tonic/cached_dataset.py\", line 137, in __getitem__\n    data, targets = load_from_disk_cache(file_path)\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/tonic/cached_dataset.py\", line 214, in load_from_disk_cache\n    for index in f[name].keys():\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/home/zxh/.conda/envs/xiaohan/lib/python3.8/site-packages/h5py/_hl/group.py\", line 328, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\nKeyError: \"Unable to open object (object 'target' doesn't exist)\"\n"
     ]
    }
   ],
   "source": [
    "train_network(net, num_epochs, F.accuracy_rate, loss_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-xiaohan-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-xiaohan] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}