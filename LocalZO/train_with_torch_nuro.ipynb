{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Serious of transformations using tonic\n",
    "* Step1: load from the tonic.datasets.Dataset\n",
    "* Step2: apply transformation defined in tonic.transforms, like Denoise, ToFrame\n",
    "* Step3: warp the dataset using a CachedDataset, which will cache the transformed data to disk\n",
    "* Step4: apply transformation to the frame (output from ToFrame), here we can use torch and torchvision transforms\n",
    "* Step5: warp the dataset using dataloader, but be aware of collate_fn, where we need to pad the frame to the same length\n",
    "* Step6: check if the result has shape [time, batch, channel, height, width] according to argument 'batch_first' in collate_fn, make sure we have time-first dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import tonic\n",
    "\n",
    "# download the dataset from tonic\n",
    "dataset = tonic.datasets.NMNIST(save_to='./data', train=True)\n",
    "events, target = dataset[0]\n",
    "events"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tonic.transforms as transforms\n",
    "\n",
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "# remove isolated events\n",
    "# sum a period of events into a frame\n",
    "frame_transform = transforms.Compose([\n",
    "    transforms.Denoise(filter_time=10000),\n",
    "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000),\n",
    "])\n",
    "trainset = tonic.datasets.NMNIST(save_to='./data', train=True, transform=frame_transform)\n",
    "testset = tonic.datasets.NMNIST(save_to='./data', train=False, transform=frame_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 312, 2, 34, 34])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "# then load the dataset the cache to accelerate data loading\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./data/cache')\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./data/cache')\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(cached_trainset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=tonic.collation.PadTensors())\n",
    "test_loader = DataLoader(cached_testset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=tonic.collation.PadTensors())\n",
    "\n",
    "# check the shape of input\n",
    "next(iter(train_loader))[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([310, 128, 2, 34, 34])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import functools\n",
    "\n",
    "transform = tonic.transforms.Compose([\n",
    "    torch.from_numpy,\n",
    "    torchvision.transforms.RandomRotation([-10,10]),\n",
    "])\n",
    "\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./data/cache', transform=transform)\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./data/cache',)\n",
    "\n",
    "# here, we need to pad the frame to the same length by using collate_fn\n",
    "# we then make time-first dataset by setting batch_first=False\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(cached_trainset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "test_loader = DataLoader(cached_testset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4,\n",
    "                        collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "\n",
    "# check the shape of input\n",
    "next(iter(train_loader))[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# define the network\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as F\n",
    "from snntorch import spikeplot as splt\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# define the forward pass\n",
    "\n",
    "def forward(net, data):\n",
    "    spk_rec = []\n",
    "    utils.reset(net)\n",
    "\n",
    "    for step in range(data.size(0)):\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "\n",
    "    return torch.stack(spk_rec, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([12, 2, 5, 5]) Parameter containing:\n",
      "tensor([[[[-1.3953e-01, -3.4276e-02, -8.1970e-02,  1.2021e-01, -1.2712e-02],\n",
      "          [ 5.0660e-02, -9.4248e-02, -9.2561e-02, -1.4381e-02,  1.2923e-02],\n",
      "          [-8.7153e-02, -1.4990e-02,  1.3184e-01,  1.2049e-01, -1.3423e-02],\n",
      "          [ 3.3373e-02, -4.5185e-02, -8.4980e-03, -3.8353e-02, -1.2358e-01],\n",
      "          [ 3.4303e-02,  6.3928e-02, -8.7856e-02, -1.0617e-01, -9.7366e-02]],\n",
      "\n",
      "         [[-8.2755e-02,  5.7780e-02, -9.6548e-02,  1.0910e-01, -8.0323e-02],\n",
      "          [-5.0130e-03, -4.2852e-02,  6.9761e-02,  1.0423e-01,  3.9145e-02],\n",
      "          [-3.8276e-02, -3.6343e-02,  4.9781e-02,  5.2419e-02,  3.4715e-02],\n",
      "          [-3.1870e-02,  7.6221e-02, -6.4591e-02,  9.8999e-02,  1.3774e-01],\n",
      "          [ 7.8932e-02,  5.0024e-03, -1.0149e-01,  1.2215e-01, -1.1562e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3402e-02, -1.0947e-01, -2.3540e-02,  7.2359e-02,  1.2698e-02],\n",
      "          [-7.6023e-02, -1.0713e-01, -1.3528e-01,  1.0426e-01, -2.1735e-02],\n",
      "          [-3.0799e-02,  1.2504e-01, -1.0864e-02,  5.0223e-02,  1.4429e-02],\n",
      "          [-5.1658e-02, -4.2403e-04,  5.0806e-02,  9.0386e-03,  7.3416e-02],\n",
      "          [-9.7703e-02, -2.3834e-02,  2.9752e-02, -6.6164e-02, -4.5574e-02]],\n",
      "\n",
      "         [[-2.9370e-02,  1.0267e-01,  4.2532e-02,  1.2651e-02, -1.2906e-01],\n",
      "          [-8.4952e-02,  9.7123e-03,  2.3387e-02, -4.9482e-02, -6.3198e-02],\n",
      "          [ 4.7345e-02, -8.7031e-02,  1.1839e-01,  3.9577e-02,  5.0191e-02],\n",
      "          [-6.2428e-02,  2.2343e-02,  1.4019e-01, -6.5680e-02, -4.1501e-02],\n",
      "          [-4.3427e-02, -4.7692e-02,  1.2015e-01,  1.9780e-02, -1.3646e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1396e-02,  9.8209e-02, -6.1098e-02,  2.1669e-02, -7.9776e-02],\n",
      "          [ 4.6956e-02, -1.0722e-01,  7.5334e-02,  1.0348e-01,  8.1310e-02],\n",
      "          [-1.2199e-01,  1.2878e-01,  2.7159e-02,  1.3131e-01, -2.6031e-02],\n",
      "          [-1.1887e-01,  1.0312e-01, -3.6200e-02,  1.2243e-01,  7.7599e-02],\n",
      "          [-5.4063e-02, -1.1662e-01, -1.1005e-01,  6.2022e-02, -8.0697e-02]],\n",
      "\n",
      "         [[-9.7296e-02,  1.1025e-02, -1.2789e-01, -1.0663e-02, -1.0437e-01],\n",
      "          [-5.7182e-02,  6.8641e-02, -7.3908e-02,  8.7958e-02,  1.2111e-01],\n",
      "          [ 3.7832e-02,  4.1866e-02, -8.8166e-02,  5.7381e-02,  3.9514e-02],\n",
      "          [-7.2422e-02, -1.8706e-02,  7.5785e-02, -7.7355e-02, -3.0704e-02],\n",
      "          [ 8.2532e-02, -1.0299e-01,  1.1693e-01, -1.3092e-01,  7.3170e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0634e-01, -7.4197e-02,  7.6379e-02, -6.0495e-03,  6.9643e-02],\n",
      "          [ 1.0099e-01, -3.1346e-03,  7.9038e-02,  8.5734e-02, -6.1193e-03],\n",
      "          [ 8.0863e-03,  1.2611e-01,  5.0298e-02, -5.1189e-02,  4.2530e-02],\n",
      "          [ 1.3704e-01,  4.0476e-02, -8.6738e-04,  9.3293e-02,  6.4598e-02],\n",
      "          [ 4.6257e-02,  1.3535e-01,  3.5651e-02,  2.1601e-02,  1.0295e-01]],\n",
      "\n",
      "         [[-7.0293e-04,  1.5166e-02,  2.1830e-02,  2.1132e-02, -4.2967e-02],\n",
      "          [-2.7193e-02, -1.3727e-01,  1.1284e-01,  5.4014e-02, -4.1592e-02],\n",
      "          [-1.1489e-01,  5.8165e-02,  1.3426e-01,  1.2239e-01, -1.2923e-01],\n",
      "          [-1.1024e-01,  1.3574e-02, -6.1035e-02,  5.2371e-02,  4.0705e-02],\n",
      "          [ 7.7868e-02, -2.2648e-02,  1.8452e-02,  7.3342e-02,  4.0432e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0563e-01, -9.9625e-02, -8.8786e-02, -9.8616e-02,  8.5542e-02],\n",
      "          [-9.5475e-02,  8.8153e-02,  9.5223e-02, -1.2208e-01,  6.5552e-03],\n",
      "          [-1.0685e-01,  7.5066e-02,  5.9563e-02,  6.9173e-02,  1.1152e-01],\n",
      "          [-5.2291e-02, -6.8597e-02, -4.2527e-02, -1.1067e-01, -7.8221e-02],\n",
      "          [ 5.6286e-02,  5.0827e-03,  1.2191e-01,  9.5159e-02,  5.0374e-02]],\n",
      "\n",
      "         [[ 9.9128e-02, -1.4046e-01,  5.6531e-02,  1.3911e-01, -5.4047e-02],\n",
      "          [ 5.9653e-02, -4.6260e-03,  6.3446e-02, -1.0865e-01, -4.9991e-02],\n",
      "          [ 5.3981e-02, -5.3531e-02, -1.1512e-01, -9.2180e-02,  2.0442e-02],\n",
      "          [ 7.0530e-02,  1.2723e-01, -1.9278e-02, -1.1840e-01, -1.0603e-01],\n",
      "          [-9.9281e-05,  1.1805e-01, -5.3008e-02, -6.0513e-02, -6.7532e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7832e-02,  7.4066e-02,  1.0567e-01,  3.2221e-02,  2.6245e-02],\n",
      "          [ 2.3164e-02,  7.6095e-02, -2.0333e-02,  1.2104e-01, -1.1232e-01],\n",
      "          [ 1.0642e-01, -1.7708e-02,  1.0234e-01, -1.2472e-02,  6.7247e-02],\n",
      "          [ 2.2480e-02, -4.1212e-02,  9.7408e-03,  8.0116e-02, -1.2457e-01],\n",
      "          [ 2.8296e-02, -2.0705e-02,  1.1652e-01,  1.0804e-01, -1.7535e-02]],\n",
      "\n",
      "         [[-9.5123e-02, -8.7658e-02,  4.3793e-02, -1.2758e-01, -1.0742e-01],\n",
      "          [-6.5258e-02, -7.2057e-02,  2.6348e-02, -1.3154e-01,  1.0881e-01],\n",
      "          [-6.3813e-02, -9.8158e-02,  9.2024e-02, -1.0479e-01,  1.2236e-01],\n",
      "          [ 1.2959e-01,  6.1334e-02,  7.2094e-02,  3.0700e-02,  4.4817e-02],\n",
      "          [ 1.3266e-01, -7.5175e-02, -1.3970e-01, -1.2910e-01,  1.2385e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3303e-01,  2.5335e-02, -1.1529e-01, -1.2773e-01,  1.1131e-01],\n",
      "          [ 1.2693e-01, -1.0467e-01,  5.2144e-02,  1.2603e-01, -4.2801e-02],\n",
      "          [ 3.6971e-02, -1.0435e-01, -1.0007e-01,  8.5362e-02,  1.1716e-01],\n",
      "          [ 7.8519e-02, -1.0738e-01, -2.8357e-02, -6.9470e-02,  8.7589e-02],\n",
      "          [-4.6241e-02, -3.3585e-03, -1.0895e-01,  8.6433e-02,  5.3382e-02]],\n",
      "\n",
      "         [[ 8.1065e-02,  1.3841e-01, -9.8891e-02, -9.8437e-02,  1.1037e-01],\n",
      "          [ 1.1425e-01, -3.7932e-02,  1.3141e-01, -1.2210e-01, -9.1155e-02],\n",
      "          [-1.1301e-01, -1.1332e-01, -7.3632e-02, -1.3715e-01, -7.5756e-02],\n",
      "          [-1.7376e-02,  4.5999e-02, -4.8957e-02, -1.2834e-01,  6.1941e-02],\n",
      "          [ 3.8394e-02, -3.6461e-02, -1.0024e-01, -1.2663e-01,  1.3212e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1210e-01,  1.3209e-01, -5.2014e-02, -9.1651e-02, -5.0362e-02],\n",
      "          [ 2.2285e-02,  1.0041e-01,  1.4018e-01,  5.7405e-02, -1.7875e-02],\n",
      "          [ 1.1701e-01, -9.8584e-02, -7.7939e-02,  1.0906e-01, -4.0317e-02],\n",
      "          [ 5.8160e-02, -5.2864e-02,  9.8713e-02,  1.3987e-01, -3.5745e-02],\n",
      "          [ 6.5189e-02, -6.3996e-03,  5.5020e-02, -1.0882e-01,  3.0023e-02]],\n",
      "\n",
      "         [[ 1.1605e-01, -6.8159e-02,  9.2558e-02, -1.1593e-01, -7.0564e-02],\n",
      "          [-4.3324e-02, -6.4992e-02, -1.3242e-02, -8.1028e-02,  3.1303e-02],\n",
      "          [-6.7965e-02,  2.6462e-03,  1.5149e-02, -1.0357e-01,  4.4523e-03],\n",
      "          [-9.7041e-02, -1.3568e-01,  3.8469e-02,  6.5778e-02, -6.3660e-02],\n",
      "          [-7.2638e-02, -6.0629e-02,  1.1104e-01,  2.9115e-05,  5.1691e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8025e-02,  1.3542e-01, -2.9188e-02,  8.6889e-02,  3.9868e-02],\n",
      "          [-3.3380e-02, -1.1140e-01,  9.6181e-02,  6.9773e-02, -4.5721e-02],\n",
      "          [-1.5241e-02,  5.1448e-02, -1.0097e-01,  7.6647e-02,  1.1408e-01],\n",
      "          [ 8.0800e-02,  2.3135e-04, -4.6220e-02, -9.6516e-02,  3.2404e-02],\n",
      "          [ 1.1640e-01, -1.4638e-02,  8.0659e-02, -1.3679e-01,  6.5076e-02]],\n",
      "\n",
      "         [[-1.0590e-01, -1.3680e-01,  8.4922e-02, -1.0669e-02, -1.4141e-01],\n",
      "          [ 1.3242e-01,  5.3967e-02, -7.3280e-02,  4.0492e-02,  5.6814e-02],\n",
      "          [-1.3299e-01,  1.3084e-01, -1.1874e-01,  9.2911e-02, -8.1879e-02],\n",
      "          [ 7.5751e-03,  6.0377e-02, -5.7166e-02, -8.7942e-02,  4.2175e-02],\n",
      "          [-4.4747e-02,  7.4071e-03, -6.3480e-02,  1.1235e-01, -8.8950e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0530e-01,  2.6277e-03, -1.2331e-01,  3.6136e-02,  1.6557e-02],\n",
      "          [-1.0595e-01,  5.9090e-02,  1.7212e-02,  1.6745e-02,  7.9087e-02],\n",
      "          [-1.3857e-01, -1.5464e-02,  1.0408e-01,  4.9398e-02,  1.1317e-02],\n",
      "          [ 1.0993e-01,  7.2613e-02,  1.9746e-02, -5.8491e-02, -7.3049e-03],\n",
      "          [ 6.0548e-02,  7.1271e-02, -2.8644e-02, -1.2847e-01,  3.1960e-02]],\n",
      "\n",
      "         [[-1.0813e-01,  8.8479e-02, -5.5823e-02, -7.9508e-02,  2.8149e-02],\n",
      "          [ 1.1582e-01, -2.3945e-02, -1.0167e-01,  5.1427e-02,  2.9521e-02],\n",
      "          [ 8.4482e-02,  7.0861e-02,  1.2821e-01,  1.4007e-01, -1.3039e-01],\n",
      "          [-4.9723e-02, -5.0082e-02,  1.1615e-01, -9.5671e-03, -3.2382e-02],\n",
      "          [ 3.6930e-02, -3.6262e-02,  1.7426e-02,  6.5778e-02,  8.5316e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0783e-01,  8.3636e-02,  8.2459e-02, -6.7042e-02, -1.3626e-01],\n",
      "          [-3.4113e-02,  9.1684e-03,  3.1398e-02,  1.4801e-02, -3.0166e-02],\n",
      "          [ 1.9322e-02, -2.1098e-02,  6.2354e-02, -2.7566e-03,  4.4391e-02],\n",
      "          [-1.1136e-01,  5.2350e-02,  1.1398e-01,  6.5039e-02,  9.8910e-02],\n",
      "          [-2.1046e-02,  1.1694e-02,  7.5346e-03,  1.6725e-03, -3.7140e-02]],\n",
      "\n",
      "         [[ 1.1447e-01, -1.1235e-01,  2.3982e-02, -7.4183e-02, -9.7138e-02],\n",
      "          [-1.1715e-01,  3.4284e-02, -9.4256e-02, -7.2716e-02,  1.3990e-01],\n",
      "          [-1.0954e-01, -1.2457e-01, -5.1218e-02, -9.4649e-02,  4.8782e-02],\n",
      "          [-3.4425e-02,  8.8051e-03,  1.3149e-01,  7.2346e-02, -2.6569e-02],\n",
      "          [-1.3557e-02,  9.8050e-02, -3.8942e-02,  7.3005e-02,  5.5043e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0680e-01, -1.2674e-02, -8.3018e-03, -1.3082e-01, -8.9320e-02],\n",
      "          [ 1.6767e-02,  1.1598e-01, -9.3599e-02,  4.3779e-02,  1.0335e-01],\n",
      "          [-2.6511e-02,  5.7591e-02,  1.4409e-03,  6.7961e-02,  4.5465e-02],\n",
      "          [ 2.0470e-02, -4.8995e-02,  2.1766e-02, -7.8388e-02,  8.0367e-02],\n",
      "          [ 9.3047e-02, -7.7072e-02,  6.5819e-02, -1.1436e-01,  1.3234e-01]],\n",
      "\n",
      "         [[ 5.0321e-02,  1.2580e-01, -1.1605e-01,  1.9499e-02,  5.4475e-03],\n",
      "          [-1.3958e-01, -5.3664e-02,  8.1278e-02, -1.2767e-01,  1.6032e-02],\n",
      "          [-1.2711e-02,  5.1078e-02,  8.8511e-02, -4.0727e-02,  1.3701e-01],\n",
      "          [-6.0995e-02, -1.4103e-01, -1.0858e-01, -1.0646e-01, -9.0797e-02],\n",
      "          [ 1.3872e-01, -4.7873e-02,  8.8621e-02, -2.8990e-03,  1.3129e-01]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "conv1.bias torch.Size([12]) Parameter containing:\n",
      "tensor([-0.1212,  0.0861,  0.0390,  0.0269,  0.0400,  0.1258,  0.0967,  0.1261,\n",
      "        -0.0043, -0.0788,  0.0805, -0.0037], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "conv2.weight torch.Size([32, 12, 5, 5]) Parameter containing:\n",
      "tensor([[[[-1.8128e-02,  2.9857e-02, -1.6404e-02,  4.9955e-02,  1.3150e-02],\n",
      "          [ 5.2944e-02, -3.6817e-02,  2.8231e-02, -3.6710e-02,  4.4398e-02],\n",
      "          [ 1.4975e-02, -5.5049e-02,  5.0747e-02, -1.4755e-02,  5.2233e-02],\n",
      "          [-2.8831e-02, -1.9236e-02,  2.3055e-02, -4.7897e-02,  5.3505e-02],\n",
      "          [ 2.4496e-02, -2.7195e-02,  3.2921e-02, -3.8990e-02, -3.4138e-02]],\n",
      "\n",
      "         [[-4.1409e-02, -4.6297e-02,  2.3762e-02, -8.3251e-03, -1.5764e-02],\n",
      "          [ 4.8912e-02,  1.7390e-02,  9.0055e-03,  3.5165e-02, -6.2521e-03],\n",
      "          [-3.5152e-02,  2.9042e-02, -4.8775e-02,  3.2150e-02,  4.3111e-02],\n",
      "          [ 4.9232e-02, -3.7937e-02,  1.9396e-02, -3.0476e-02, -1.6315e-02],\n",
      "          [ 5.3282e-02, -3.6719e-02, -1.8088e-02, -3.4997e-02,  3.3110e-02]],\n",
      "\n",
      "         [[ 3.7352e-02, -1.2963e-02, -6.6363e-04,  2.7991e-02, -9.9155e-04],\n",
      "          [ 2.1838e-02, -1.9777e-02,  3.9161e-02, -5.3436e-02,  2.5545e-02],\n",
      "          [ 5.4545e-02, -5.4997e-02,  3.8256e-02, -4.3354e-02,  1.5662e-02],\n",
      "          [-2.6133e-02,  4.1327e-02,  5.5325e-02,  3.3831e-02,  1.3916e-02],\n",
      "          [ 3.7621e-02, -2.2788e-02,  3.6178e-02, -3.5168e-02,  2.8009e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6361e-02, -1.8314e-03, -3.1782e-03, -1.2231e-02, -1.4974e-02],\n",
      "          [ 1.2288e-02, -1.4206e-02,  3.4429e-02,  9.0839e-03,  2.2295e-02],\n",
      "          [-5.4867e-02, -2.2511e-02,  2.5820e-02,  5.0983e-02, -3.1338e-02],\n",
      "          [-5.9539e-03, -2.7394e-02, -2.2804e-02,  3.9330e-02,  2.1894e-02],\n",
      "          [ 4.5099e-02,  4.9639e-02, -2.6802e-02,  2.9925e-02,  5.0155e-02]],\n",
      "\n",
      "         [[-1.0388e-02,  1.0056e-03,  5.3903e-02, -6.1731e-03,  5.1282e-02],\n",
      "          [ 2.0804e-04,  5.7311e-02,  1.4219e-02, -8.3186e-03,  1.3295e-02],\n",
      "          [-1.4618e-02,  2.8654e-02, -3.0399e-02,  4.1574e-02,  3.4688e-02],\n",
      "          [ 1.8622e-02,  4.7341e-02, -2.1992e-02, -2.1321e-02,  4.2118e-02],\n",
      "          [-5.4201e-02, -3.1499e-02,  3.6305e-02,  3.7032e-02,  2.3511e-03]],\n",
      "\n",
      "         [[ 9.2082e-03, -1.5816e-02, -5.0126e-02,  3.8614e-02, -4.7921e-02],\n",
      "          [-1.2654e-02,  2.7874e-04, -5.7564e-02,  4.4670e-02, -2.5702e-02],\n",
      "          [-5.6966e-02, -5.3111e-02, -2.3725e-02, -2.5288e-02, -5.0373e-02],\n",
      "          [-1.8184e-02,  2.0554e-02,  1.8042e-02,  1.7830e-02, -2.8843e-02],\n",
      "          [-4.6658e-02, -5.6374e-02,  5.6551e-02, -1.0468e-02, -5.7433e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3923e-02, -5.6807e-02, -4.1890e-02, -3.4948e-02, -5.6443e-02],\n",
      "          [-5.4781e-02, -1.1942e-02, -2.1698e-02, -1.3000e-04,  4.8060e-02],\n",
      "          [-3.0304e-02,  2.3567e-02, -1.2706e-02,  1.1873e-02, -4.4329e-02],\n",
      "          [-4.3650e-02, -1.6763e-02,  1.1531e-02,  7.4487e-03, -1.5625e-02],\n",
      "          [-3.9850e-02, -7.7061e-03,  3.8870e-02,  1.2808e-02, -4.5943e-02]],\n",
      "\n",
      "         [[ 3.1176e-04, -3.0717e-02, -5.3615e-02,  3.5244e-03, -5.0003e-03],\n",
      "          [-3.1969e-02, -4.2613e-02, -1.6804e-02, -3.1300e-02, -1.1620e-03],\n",
      "          [ 4.0816e-02, -1.3074e-02,  4.3749e-02,  1.8095e-02, -5.3193e-02],\n",
      "          [-2.5291e-02,  2.3017e-02,  2.2475e-02,  5.5000e-02,  4.9175e-02],\n",
      "          [ 6.2271e-03,  4.3085e-02, -1.0792e-02,  1.5077e-03,  4.2504e-02]],\n",
      "\n",
      "         [[-1.5693e-02,  4.2614e-02,  2.5995e-02,  2.7605e-02,  2.7003e-02],\n",
      "          [-3.0377e-02,  2.5983e-02, -3.9267e-02, -1.9558e-02, -2.3386e-02],\n",
      "          [-3.4201e-02, -6.0403e-03, -4.8371e-02, -2.6848e-03,  3.3329e-02],\n",
      "          [ 3.6328e-03,  3.3062e-03,  2.0180e-03, -5.6032e-02, -5.1988e-02],\n",
      "          [ 3.6901e-02, -5.3758e-02,  9.6742e-03,  3.6044e-02,  5.0875e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6390e-02, -2.4058e-02, -5.2163e-02,  4.9679e-02,  4.5472e-02],\n",
      "          [ 3.3540e-02, -2.1408e-02, -4.6199e-02,  9.6230e-03, -5.3253e-02],\n",
      "          [ 1.8630e-02, -3.6734e-02,  8.3488e-04,  1.0611e-02, -2.2640e-02],\n",
      "          [ 2.6483e-02,  1.9581e-02, -3.1708e-02,  4.2438e-02, -4.7767e-02],\n",
      "          [-3.7551e-02,  4.3176e-03, -4.8133e-02, -4.1356e-02,  3.2610e-02]],\n",
      "\n",
      "         [[-2.2983e-03, -4.9843e-02, -8.4749e-03,  2.6570e-03,  4.4554e-03],\n",
      "          [-4.2559e-02, -4.2548e-02, -4.0840e-02, -8.4566e-03,  2.3127e-02],\n",
      "          [-5.8303e-03,  4.3676e-02, -1.0383e-02,  3.8146e-02, -2.8688e-02],\n",
      "          [-4.9344e-02, -1.6308e-02, -2.4506e-02, -4.2586e-03, -1.1545e-02],\n",
      "          [ 1.7293e-02, -3.2892e-02,  2.1321e-02,  4.8383e-02, -3.3657e-02]],\n",
      "\n",
      "         [[-3.5908e-02, -3.9707e-03,  4.1589e-02, -3.0575e-02, -4.7695e-02],\n",
      "          [ 1.3143e-03, -2.7408e-02,  4.4764e-02,  1.2176e-03, -2.8659e-02],\n",
      "          [-2.6037e-02, -5.1961e-03, -1.7443e-02,  3.3547e-02, -5.5490e-02],\n",
      "          [-2.7677e-02,  5.0865e-02,  2.3104e-02,  3.9841e-02, -6.4860e-03],\n",
      "          [ 2.7010e-02, -1.9469e-03, -4.2956e-03,  1.9621e-02,  3.5746e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6518e-02,  3.4093e-02,  3.0571e-02, -2.3437e-02, -6.1093e-03],\n",
      "          [ 4.0837e-02, -2.2595e-03, -2.9171e-02, -3.0335e-02, -5.4562e-02],\n",
      "          [-3.5070e-02, -5.3763e-02, -3.5624e-03, -5.0836e-02, -3.3151e-02],\n",
      "          [-5.2735e-02, -7.1113e-03, -2.8899e-02,  5.5011e-02,  1.2378e-02],\n",
      "          [ 3.1053e-02, -5.6813e-02,  5.2829e-02,  5.4570e-02,  1.6844e-02]],\n",
      "\n",
      "         [[ 2.4927e-02,  4.3578e-02, -2.7580e-02, -4.6498e-03,  1.1198e-02],\n",
      "          [ 1.4446e-02,  4.8130e-02, -2.7578e-03, -6.1654e-03, -1.0672e-02],\n",
      "          [ 1.2085e-02, -3.8809e-02, -3.2801e-02,  4.9935e-02,  3.6125e-03],\n",
      "          [ 2.2284e-02, -4.5848e-02, -5.1830e-02,  3.9812e-02,  2.3793e-02],\n",
      "          [-1.2649e-02, -3.6244e-02,  2.1444e-02,  1.7294e-02,  8.3846e-03]],\n",
      "\n",
      "         [[ 3.3952e-02,  2.9548e-02, -3.7589e-03,  4.1127e-02, -6.2619e-03],\n",
      "          [-3.4509e-02,  5.3720e-02, -2.0440e-02, -1.5538e-02,  1.5096e-03],\n",
      "          [ 2.0240e-02,  3.4365e-02, -2.1416e-02,  1.9190e-02, -3.3963e-02],\n",
      "          [-3.2273e-02, -2.9668e-02,  5.1729e-02,  1.2431e-02,  1.1829e-03],\n",
      "          [-5.5767e-02,  3.5072e-02,  5.7858e-03,  1.0030e-03, -4.0668e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1188e-03, -4.7727e-02, -4.7465e-02, -2.2966e-02, -3.8816e-02],\n",
      "          [ 5.2161e-03,  1.9725e-02, -2.9556e-02,  4.8222e-02,  3.8941e-02],\n",
      "          [ 1.2840e-02,  5.1406e-02, -4.7257e-02, -2.3586e-02,  8.6112e-04],\n",
      "          [ 1.4218e-02, -3.1425e-02,  5.0103e-02, -1.2344e-02, -3.4398e-02],\n",
      "          [ 4.1130e-02, -4.6825e-02,  5.1763e-02, -3.9088e-02, -2.7460e-02]],\n",
      "\n",
      "         [[-3.6632e-03, -4.2090e-02,  3.7691e-02, -4.9116e-02, -3.6607e-02],\n",
      "          [-3.9455e-02, -1.1193e-02,  1.9008e-02, -4.9098e-02, -4.8449e-02],\n",
      "          [ 2.4335e-02,  4.3825e-03, -2.6395e-02,  4.6921e-02, -4.1662e-03],\n",
      "          [-5.1252e-03, -5.4559e-03, -1.6528e-02, -2.3245e-02,  5.2116e-02],\n",
      "          [ 4.3283e-02, -5.3494e-02, -2.1252e-02,  1.6602e-02,  7.9601e-03]],\n",
      "\n",
      "         [[-1.5741e-02,  4.0763e-02,  3.2417e-02,  3.5863e-02, -4.6946e-02],\n",
      "          [-3.6752e-02, -2.9888e-02,  5.4317e-02, -5.3287e-03,  1.0466e-02],\n",
      "          [ 4.6782e-02,  1.3131e-02, -2.8377e-02,  4.7884e-02,  2.2802e-02],\n",
      "          [ 3.7663e-02, -5.3420e-02, -2.8516e-02,  3.5216e-02, -5.6121e-02],\n",
      "          [-5.8884e-03,  3.3487e-02,  5.1464e-02,  4.9443e-02,  5.7445e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.9466e-02, -2.3638e-02,  2.4350e-02, -9.5415e-03,  7.0001e-03],\n",
      "          [ 4.7076e-02, -3.0881e-02,  1.3307e-02, -1.4619e-02,  1.8140e-02],\n",
      "          [-2.4150e-02,  1.0645e-02,  5.5883e-02,  2.7000e-02,  5.0285e-02],\n",
      "          [ 4.2638e-02, -2.9911e-02,  4.6088e-02,  3.5136e-02, -1.0044e-02],\n",
      "          [ 9.1042e-03, -3.7800e-02,  7.2519e-04,  3.4287e-02, -5.2308e-02]],\n",
      "\n",
      "         [[ 3.5030e-04,  1.4716e-02, -1.7390e-02,  4.8832e-02, -4.2059e-03],\n",
      "          [ 1.2262e-02, -1.4822e-02, -3.8688e-03,  9.2018e-03,  2.1190e-02],\n",
      "          [ 3.1968e-02,  4.3621e-03,  5.1899e-02, -4.7357e-02,  3.8479e-02],\n",
      "          [-1.7805e-02, -1.9561e-02,  5.6455e-02,  3.3776e-02,  3.0032e-02],\n",
      "          [ 4.6375e-02, -2.5048e-02, -1.3110e-02, -3.1239e-02,  3.9189e-02]],\n",
      "\n",
      "         [[-5.7181e-02,  4.8593e-02, -4.5414e-02,  1.0309e-02, -5.7612e-02],\n",
      "          [-1.1815e-02, -1.5447e-02, -1.9332e-02,  3.1863e-02, -5.5771e-02],\n",
      "          [-3.3345e-02,  4.7220e-03, -2.1816e-02,  4.1686e-02,  2.4981e-03],\n",
      "          [ 3.5441e-02,  1.5866e-02, -1.9590e-02, -1.8517e-02, -5.3037e-02],\n",
      "          [-7.4993e-03, -2.8298e-02, -2.8928e-02, -2.8553e-02,  3.6784e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0690e-02,  5.5154e-02,  5.9915e-03, -3.7431e-02, -4.5410e-02],\n",
      "          [ 5.1604e-02,  1.5422e-02,  3.6604e-02,  8.3362e-03, -1.4417e-02],\n",
      "          [ 2.1884e-02,  5.2514e-02, -7.5319e-03, -1.8860e-02,  6.5528e-03],\n",
      "          [ 3.4868e-02, -5.4205e-02,  4.1400e-02, -3.9723e-02,  1.1154e-02],\n",
      "          [-3.2927e-02,  3.6513e-02, -4.8550e-05,  3.9094e-02,  1.2740e-02]],\n",
      "\n",
      "         [[-1.1633e-02,  1.5280e-02, -8.1249e-03,  5.7365e-02,  1.6216e-02],\n",
      "          [ 9.8993e-03, -5.0140e-03, -2.5572e-02,  2.4612e-02,  5.4559e-02],\n",
      "          [-2.3517e-02, -4.5871e-02, -3.8185e-02, -4.2242e-02, -5.0871e-02],\n",
      "          [-2.7348e-02, -2.4782e-02,  4.2958e-02,  4.6544e-02,  8.1739e-03],\n",
      "          [ 3.6193e-02, -2.4949e-02,  3.8406e-02,  2.0261e-02,  4.3651e-02]],\n",
      "\n",
      "         [[ 3.8294e-02,  3.2289e-03, -4.9194e-02,  1.4508e-02, -3.7555e-02],\n",
      "          [ 4.8365e-02,  2.4877e-02,  2.5470e-02,  1.4677e-02,  3.1285e-02],\n",
      "          [-4.0716e-02, -3.1111e-04,  3.7565e-02, -2.5558e-02, -1.6257e-02],\n",
      "          [-1.9174e-02,  3.4323e-02, -4.1083e-02, -4.1447e-03,  1.4871e-02],\n",
      "          [ 1.9969e-02, -4.4659e-02, -1.3244e-02,  3.5870e-02, -5.4329e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.5838e-03, -2.6412e-02,  4.0794e-02,  1.5141e-02,  2.8731e-02],\n",
      "          [ 2.0355e-02,  5.7270e-02, -4.4907e-02,  4.4190e-02,  3.1875e-02],\n",
      "          [-2.8509e-02,  2.4569e-02, -3.0124e-02, -4.4709e-02, -3.4037e-02],\n",
      "          [-2.0320e-03, -4.8862e-02, -9.9623e-03,  4.8721e-02,  2.2599e-02],\n",
      "          [ 1.8099e-02, -2.1736e-02, -1.6048e-02,  3.5610e-02,  1.1213e-02]],\n",
      "\n",
      "         [[-3.7939e-02,  3.5599e-02,  2.7838e-02, -5.7720e-02, -3.8851e-02],\n",
      "          [-2.1570e-02,  5.7419e-02, -2.5948e-02,  2.5369e-02, -1.9783e-02],\n",
      "          [-9.5140e-04,  3.5394e-02, -5.3502e-02,  4.0411e-03,  5.3836e-03],\n",
      "          [ 4.8590e-02, -1.6158e-03,  5.7208e-02, -4.6328e-02,  3.9588e-02],\n",
      "          [-3.5212e-03,  1.0030e-03,  3.4921e-02, -2.5985e-02,  3.8964e-02]],\n",
      "\n",
      "         [[-3.4357e-02,  2.5837e-02, -6.8663e-03, -2.8204e-02,  4.9702e-02],\n",
      "          [ 1.7801e-02,  2.9716e-02, -2.3381e-02,  5.2341e-02, -4.4898e-02],\n",
      "          [-2.1682e-02, -1.6879e-02, -3.9910e-02, -2.7174e-03, -2.5718e-02],\n",
      "          [ 1.5661e-02,  1.4060e-02, -2.7823e-02, -2.8218e-02, -1.7610e-02],\n",
      "          [ 1.2945e-02,  3.7879e-02, -1.8098e-03,  5.2167e-02, -6.4412e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5344e-02, -4.8657e-02,  1.9517e-02,  7.3714e-03, -1.1753e-02],\n",
      "          [ 3.1247e-02,  4.1730e-02,  3.4932e-02, -9.9625e-03,  5.6526e-02],\n",
      "          [ 1.8556e-02, -3.0192e-03, -4.8287e-02,  4.9210e-02, -4.8510e-02],\n",
      "          [ 3.2436e-02, -3.8247e-02, -3.3957e-02,  4.3451e-02,  2.0494e-02],\n",
      "          [ 3.4039e-02, -4.4725e-03,  5.3383e-02,  1.1472e-02, -3.2249e-02]],\n",
      "\n",
      "         [[ 1.4467e-02, -2.2279e-02,  2.3601e-02,  2.1787e-02, -3.2746e-02],\n",
      "          [ 4.5857e-02, -1.2909e-02,  6.0915e-03, -3.7662e-02,  4.8744e-02],\n",
      "          [-5.0340e-02, -2.9108e-02,  4.4011e-02,  3.8767e-04,  1.5270e-03],\n",
      "          [-4.2420e-02, -2.6920e-02, -5.4645e-02, -5.3648e-03, -9.6550e-03],\n",
      "          [-2.1291e-02,  9.0520e-03, -4.0622e-02, -4.7264e-02, -3.2730e-03]],\n",
      "\n",
      "         [[-5.6723e-02, -4.1076e-03,  3.0465e-02, -2.6596e-02, -4.3599e-02],\n",
      "          [ 1.8051e-02,  2.7155e-02, -3.3571e-02,  3.2135e-02,  2.1063e-02],\n",
      "          [ 2.5852e-03,  5.3160e-02, -3.2023e-02, -4.5559e-02, -2.4529e-02],\n",
      "          [ 5.4416e-02,  5.5317e-02, -3.0530e-02, -1.0399e-03, -2.2652e-03],\n",
      "          [-5.3823e-02, -2.2632e-02,  3.7504e-02,  1.6689e-02, -1.9364e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4254e-02, -3.4925e-02,  1.9771e-02,  5.1925e-02, -4.0767e-02],\n",
      "          [-3.4067e-02,  4.5811e-02,  4.1081e-02, -4.5819e-02,  5.9112e-03],\n",
      "          [-1.9877e-03,  3.1116e-02, -4.6980e-02,  2.4332e-02,  3.5835e-02],\n",
      "          [-5.0846e-03,  2.9223e-02, -2.1188e-02,  1.0643e-02,  5.0936e-02],\n",
      "          [-5.3438e-02, -1.6874e-02,  2.2765e-02, -3.9081e-02,  5.5524e-02]],\n",
      "\n",
      "         [[ 3.2857e-03, -4.1745e-02,  6.2767e-03,  1.5230e-02,  1.9158e-02],\n",
      "          [-1.0619e-02, -3.5845e-02, -1.2968e-02,  4.3943e-02, -4.4547e-02],\n",
      "          [-2.5256e-02, -4.6121e-02, -5.0121e-02, -2.9542e-02, -4.3145e-02],\n",
      "          [-3.4919e-02, -9.9272e-03,  2.5543e-02, -5.7224e-02, -4.6189e-02],\n",
      "          [-4.0033e-02, -1.5035e-02,  2.8599e-02,  5.3491e-02, -8.2468e-03]],\n",
      "\n",
      "         [[ 7.5040e-05,  1.9084e-02,  9.8510e-03,  1.6959e-02,  9.7639e-04],\n",
      "          [ 2.4633e-02, -3.2130e-02,  2.4938e-02,  3.5356e-02,  1.4620e-02],\n",
      "          [ 1.0004e-02,  4.0781e-02,  2.7762e-02,  5.7052e-02, -2.2220e-02],\n",
      "          [ 1.6934e-02,  1.3562e-02,  1.6553e-02, -1.2919e-02, -2.1878e-02],\n",
      "          [ 3.3461e-02,  3.6672e-02,  3.1241e-02, -1.7504e-02, -3.0427e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5840e-02, -2.6613e-02,  2.6415e-02,  2.8258e-04, -2.4383e-02],\n",
      "          [-1.8337e-02,  1.0233e-02, -3.3049e-02,  5.2603e-02,  1.7640e-02],\n",
      "          [ 1.4400e-02, -1.2109e-02, -1.3601e-02, -5.4981e-02, -4.6941e-02],\n",
      "          [-1.8835e-02, -2.6576e-02,  2.7643e-02, -3.6149e-03,  1.8237e-02],\n",
      "          [ 1.8875e-04, -8.9040e-03,  5.6432e-02,  5.6032e-02,  1.8320e-02]],\n",
      "\n",
      "         [[-2.4332e-02,  5.2910e-02,  3.4636e-02,  4.0414e-02, -2.1688e-02],\n",
      "          [-1.1881e-02,  1.8201e-02, -7.6807e-03,  2.5995e-03,  1.8292e-02],\n",
      "          [ 3.9488e-02, -3.5574e-02,  3.9878e-02,  2.4447e-02, -2.6342e-02],\n",
      "          [-1.4805e-02,  3.0011e-02,  5.2267e-02,  1.0593e-02,  4.0138e-02],\n",
      "          [ 9.6012e-04,  4.3513e-02, -5.6509e-02, -1.6984e-02,  3.8534e-02]],\n",
      "\n",
      "         [[ 4.9116e-03, -3.8745e-02, -3.4042e-03,  5.3717e-02,  1.9265e-02],\n",
      "          [-2.4925e-02, -4.6199e-04, -4.4700e-02,  4.0919e-02, -4.8693e-04],\n",
      "          [-6.1927e-03, -1.2602e-02, -1.4251e-02, -1.5574e-02,  1.1904e-02],\n",
      "          [-2.3490e-03, -3.4539e-02,  5.7228e-02,  1.8794e-02,  5.7315e-02],\n",
      "          [-2.3952e-02, -3.6249e-04,  6.6668e-03, -2.7583e-02, -1.7332e-02]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "conv2.bias torch.Size([32]) Parameter containing:\n",
      "tensor([-0.0189,  0.0443,  0.0322,  0.0569, -0.0373, -0.0457,  0.0380, -0.0565,\n",
      "         0.0516, -0.0280,  0.0552,  0.0438,  0.0011, -0.0165, -0.0151,  0.0149,\n",
      "         0.0314,  0.0444, -0.0078, -0.0267, -0.0302, -0.0125,  0.0359,  0.0054,\n",
      "        -0.0005, -0.0416, -0.0247, -0.0012,  0.0421, -0.0465, -0.0338, -0.0028],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "linear.weight torch.Size([10, 800]) Parameter containing:\n",
      "tensor([[ 0.0144, -0.0116,  0.0045,  ...,  0.0079,  0.0065, -0.0099],\n",
      "        [ 0.0170, -0.0065, -0.0169,  ...,  0.0247, -0.0139, -0.0330],\n",
      "        [-0.0095,  0.0043, -0.0113,  ...,  0.0239,  0.0016,  0.0069],\n",
      "        ...,\n",
      "        [-0.0008, -0.0070,  0.0318,  ...,  0.0335,  0.0041, -0.0035],\n",
      "        [-0.0240,  0.0191,  0.0030,  ..., -0.0182,  0.0287, -0.0043],\n",
      "        [-0.0229, -0.0015,  0.0025,  ...,  0.0127,  0.0117,  0.0160]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "linear.bias torch.Size([10]) Parameter containing:\n",
      "tensor([-0.0054,  0.0032,  0.0338, -0.0282, -0.0236, -0.0140, -0.0058,  0.0069,\n",
      "        -0.0199, -0.0295], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "#  Initialize Network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 12, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.snn1 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "        self.conv2 = nn.Conv2d(12, 32, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.snn2 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(32*5*5, 10)\n",
    "        self.snn3 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.snn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.snn2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.snn3(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_sparsity(x):\n",
    "        return (x == 0).float().mean()\n",
    "\n",
    "net = SimpleNet().to(device)\n",
    "for k, v in net.named_parameters():\n",
    "    print(k, v.shape, v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-2)\n",
    "loss_fn = F.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0 \n",
      "Train Loss: 30.90, time: 1.27s\n",
      "Accuracy: 7.81%\n",
      "\n",
      "Epoch 0, Iteration 1 \n",
      "Train Loss: 30.96, time: 1.17s\n",
      "Accuracy: 6.25%\n",
      "\n",
      "Epoch 0, Iteration 2 \n",
      "Train Loss: 31.00, time: 1.20s\n",
      "Accuracy: 10.16%\n",
      "\n",
      "Epoch 0, Iteration 3 \n",
      "Train Loss: 22.32, time: 1.26s\n",
      "Accuracy: 10.16%\n",
      "\n",
      "Epoch 0, Iteration 4 \n",
      "Train Loss: 12.43, time: 1.11s\n",
      "Accuracy: 13.28%\n",
      "\n",
      "Epoch 0, Iteration 5 \n",
      "Train Loss: 16.43, time: 1.16s\n",
      "Accuracy: 13.28%\n",
      "\n",
      "Epoch 0, Iteration 6 \n",
      "Train Loss: 17.42, time: 1.14s\n",
      "Accuracy: 11.72%\n",
      "\n",
      "Epoch 0, Iteration 7 \n",
      "Train Loss: 15.54, time: 1.21s\n",
      "Accuracy: 17.19%\n",
      "\n",
      "Epoch 0, Iteration 8 \n",
      "Train Loss: 12.67, time: 1.25s\n",
      "Accuracy: 21.09%\n",
      "\n",
      "Epoch 0, Iteration 9 \n",
      "Train Loss: 12.89, time: 1.25s\n",
      "Accuracy: 17.19%\n",
      "\n",
      "Epoch 0, Iteration 10 \n",
      "Train Loss: 13.87, time: 1.29s\n",
      "Accuracy: 19.53%\n",
      "\n",
      "Epoch 0, Iteration 11 \n",
      "Train Loss: 12.81, time: 1.21s\n",
      "Accuracy: 21.88%\n",
      "\n",
      "Epoch 0, Iteration 12 \n",
      "Train Loss: 11.86, time: 1.20s\n",
      "Accuracy: 18.75%\n",
      "\n",
      "Epoch 0, Iteration 13 \n",
      "Train Loss: 12.28, time: 1.24s\n",
      "Accuracy: 14.84%\n",
      "\n",
      "Epoch 0, Iteration 14 \n",
      "Train Loss: 12.56, time: 1.21s\n",
      "Accuracy: 24.22%\n",
      "\n",
      "Epoch 0, Iteration 15 \n",
      "Train Loss: 12.84, time: 1.20s\n",
      "Accuracy: 24.22%\n",
      "\n",
      "Epoch 0, Iteration 16 \n",
      "Train Loss: 12.01, time: 1.20s\n",
      "Accuracy: 24.22%\n",
      "\n",
      "Epoch 0, Iteration 17 \n",
      "Train Loss: 11.30, time: 1.21s\n",
      "Accuracy: 25.00%\n",
      "\n",
      "Epoch 0, Iteration 18 \n",
      "Train Loss: 11.79, time: 1.23s\n",
      "Accuracy: 30.47%\n",
      "\n",
      "Epoch 0, Iteration 19 \n",
      "Train Loss: 11.49, time: 1.22s\n",
      "Accuracy: 35.94%\n",
      "\n",
      "Epoch 0, Iteration 20 \n",
      "Train Loss: 11.21, time: 1.25s\n",
      "Accuracy: 34.38%\n",
      "\n",
      "Epoch 0, Iteration 21 \n",
      "Train Loss: 10.22, time: 1.23s\n",
      "Accuracy: 38.28%\n",
      "\n",
      "Epoch 0, Iteration 22 \n",
      "Train Loss: 10.65, time: 1.21s\n",
      "Accuracy: 47.66%\n",
      "\n",
      "Epoch 0, Iteration 23 \n",
      "Train Loss: 10.43, time: 1.20s\n",
      "Accuracy: 45.31%\n",
      "\n",
      "Epoch 0, Iteration 24 \n",
      "Train Loss: 9.80, time: 1.18s\n",
      "Accuracy: 60.94%\n",
      "\n",
      "Epoch 0, Iteration 25 \n",
      "Train Loss: 10.33, time: 1.24s\n",
      "Accuracy: 58.59%\n",
      "\n",
      "Epoch 0, Iteration 26 \n",
      "Train Loss: 9.75, time: 1.27s\n",
      "Accuracy: 46.09%\n",
      "\n",
      "Epoch 0, Iteration 27 \n",
      "Train Loss: 9.56, time: 1.24s\n",
      "Accuracy: 54.69%\n",
      "\n",
      "Epoch 0, Iteration 28 \n",
      "Train Loss: 9.28, time: 1.17s\n",
      "Accuracy: 60.94%\n",
      "\n",
      "Epoch 0, Iteration 29 \n",
      "Train Loss: 8.93, time: 1.26s\n",
      "Accuracy: 56.25%\n",
      "\n",
      "Epoch 0, Iteration 30 \n",
      "Train Loss: 9.22, time: 1.25s\n",
      "Accuracy: 50.00%\n",
      "\n",
      "Epoch 0, Iteration 31 \n",
      "Train Loss: 9.10, time: 1.22s\n",
      "Accuracy: 51.56%\n",
      "\n",
      "Epoch 0, Iteration 32 \n",
      "Train Loss: 8.81, time: 1.20s\n",
      "Accuracy: 62.50%\n",
      "\n",
      "Epoch 0, Iteration 33 \n",
      "Train Loss: 8.44, time: 1.31s\n",
      "Accuracy: 62.50%\n",
      "\n",
      "Epoch 0, Iteration 34 \n",
      "Train Loss: 8.76, time: 1.26s\n",
      "Accuracy: 57.81%\n",
      "\n",
      "Epoch 0, Iteration 35 \n",
      "Train Loss: 8.41, time: 1.19s\n",
      "Accuracy: 64.06%\n",
      "\n",
      "Epoch 0, Iteration 36 \n",
      "Train Loss: 8.43, time: 1.36s\n",
      "Accuracy: 57.03%\n",
      "\n",
      "Epoch 0, Iteration 37 \n",
      "Train Loss: 7.93, time: 1.19s\n",
      "Accuracy: 65.62%\n",
      "\n",
      "Epoch 0, Iteration 38 \n",
      "Train Loss: 7.91, time: 1.21s\n",
      "Accuracy: 61.72%\n",
      "\n",
      "Epoch 0, Iteration 39 \n",
      "Train Loss: 7.83, time: 1.17s\n",
      "Accuracy: 61.72%\n",
      "\n",
      "Epoch 0, Iteration 40 \n",
      "Train Loss: 7.37, time: 1.18s\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 0, Iteration 41 \n",
      "Train Loss: 7.48, time: 1.23s\n",
      "Accuracy: 63.28%\n",
      "\n",
      "Epoch 0, Iteration 42 \n",
      "Train Loss: 6.97, time: 1.23s\n",
      "Accuracy: 65.62%\n",
      "\n",
      "Epoch 0, Iteration 43 \n",
      "Train Loss: 6.75, time: 1.22s\n",
      "Accuracy: 74.22%\n",
      "\n",
      "Epoch 0, Iteration 44 \n",
      "Train Loss: 7.46, time: 1.11s\n",
      "Accuracy: 66.41%\n",
      "\n",
      "Epoch 0, Iteration 45 \n",
      "Train Loss: 6.86, time: 1.06s\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Epoch 0, Iteration 46 \n",
      "Train Loss: 6.87, time: 1.11s\n",
      "Accuracy: 69.53%\n",
      "\n",
      "Epoch 0, Iteration 47 \n",
      "Train Loss: 6.93, time: 1.09s\n",
      "Accuracy: 68.75%\n",
      "\n",
      "Epoch 0, Iteration 48 \n",
      "Train Loss: 6.81, time: 1.07s\n",
      "Accuracy: 67.97%\n",
      "\n",
      "Epoch 0, Iteration 49 \n",
      "Train Loss: 8.92, time: 1.10s\n",
      "Accuracy: 58.59%\n",
      "\n",
      "Epoch 0, Iteration 50 \n",
      "Train Loss: 7.32, time: 1.05s\n",
      "Accuracy: 68.75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 1\n",
    "num_iters = 50\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
    "        start = time.time()\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec = forward(net, data)\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}, time: {end-start:.2f}s\")\n",
    "\n",
    "        acc = F.accuracy_rate(spk_rec, targets)\n",
    "        acc_hist.append(acc)\n",
    "        print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "        # training loop breaks after 50 iterations\n",
    "        if i == num_iters:\n",
    "          break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-xiaohan-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-xiaohan] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}